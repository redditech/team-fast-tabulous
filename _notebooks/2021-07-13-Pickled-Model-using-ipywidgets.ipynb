{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7e2183",
   "metadata": {},
   "source": [
    "# Pickled Model using ipwidgets\n",
    "> This notebook loads a previously trained model and uses it to predict quote success rate using user input to change fields. User input uses ip[\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- author: Tim Cummings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eca4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "from IPython.display import display\n",
    "from IPython.utils import io  # using io.capture_output\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef9d01",
   "metadata": {},
   "source": [
    "## Set up\n",
    "Specify the folder which contains the original kaggle data (train.csv and test.csv) and the trained model (learn_0708.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdee60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "path = Path('data/homesite-quote')\n",
    "logger = logging.getLogger(\"load_pickled_model\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76109161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_dl_pkl = \"learn_0708.pkl\"\n",
    "learn = load_pickle(path/trained_dl_pkl)\n",
    "preds, targs = learn.get_preds()\n",
    "logger.debug(f\"Trained deep learning model {trained_dl_pkl} has a roc_auc_score of {roc_auc_score(to_np(targs), to_np(preds[:,1]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962ed0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path/'train.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "df_test = pd.read_csv(path/'test.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "sr_conv = df_train['QuoteConversion_Flag']\n",
    "df_train.drop('QuoteConversion_Flag', inplace=True, axis=1)\n",
    "df = pd.concat([df_train, df_test])\n",
    "df = add_datepart(df, 'Original_Quote_Date')\n",
    "logger.debug(f\"{df.shape} {df_train.shape} {df_test.shape} {sr_conv.shape}\")\n",
    "df_train = None\n",
    "df_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ca026",
   "metadata": {},
   "source": [
    "## Create a sensitivity analysis tool\n",
    "A field is sensitive if changing the value of the field can change the outcome of the predicted quote success\n",
    "\n",
    "While logging is INFO some logging will occur during a normal run. Setting logging level to WARNING will only log if an unknown dtype is encountered. See setup above to set level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3526f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis(qn):\n",
    "    \"\"\"Using data from quote number qn do a sensitivity analysis on all independent variables\"\"\"\n",
    "    # Independent variables\n",
    "    ind_original = df.loc[qn]\n",
    "    prd = learn.predict(ind_original)\n",
    "    # Predicted quote conversion flag\n",
    "    qcf_original = prd[1].item()\n",
    "    # Probability that quote conversion flag is as predicted\n",
    "    prb_original = prd[2][qcf_original].item()\n",
    "    logger.info(f\"Sensitivity Analysis for Quote {qn}\")\n",
    "    # Check if we actually know the correct answer\n",
    "    if qn in sr_conv.index:\n",
    "        logger.info(f\"Actual QuoteConversion_Flag {sr_conv[qn]}\")\n",
    "\n",
    "    def tf_sensitive(f, v_original, lst_v, p_original):\n",
    "        \"\"\"predicts quote success after changing field f from v_original to each value in lst_v. \n",
    "        If prediction changes then quote is sensitive to the value of this field and True is returned\"\"\"\n",
    "        # Create a DataFrame which has every row identical except for field in question\n",
    "        # Field f iterates through every value provided\n",
    "        ind_other = df.loc[qn:qn].copy().drop(f, axis=1)  # fields other than f\n",
    "        ind_f = pd.DataFrame(data={f: lst_v}, index=[qn] * len(lst_v))\n",
    "        # Merge these two DataFrames to create one with all rows identical except field f\n",
    "        ind = pd.merge(ind_other, ind_f, right_index=True, left_index=True)\n",
    "        # Copy lines from learn.predict() because we want to predict several rows at once (faster than one at a time)\n",
    "        dl = learn.dls.test_dl(ind)\n",
    "        dl.dataset.conts = dl.dataset.conts.astype(np.float32)\n",
    "        # stop learn.get_preds() printing blank lines\n",
    "        with io.capture_output() as captured:\n",
    "            # using get_preds() rather than predict() because get_preds can do multiple rows at once\n",
    "            inp,preds,_,dec_preds = learn.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "        tf = False\n",
    "        # Check if any predictions changed\n",
    "        for i, dp in enumerate(dec_preds):\n",
    "            qcf = dp.item()\n",
    "            if qcf != qcf_original:\n",
    "                prb = preds[i][qcf].item()\n",
    "                logger.info(f\"Changing {f} from {val_original} to {lst_v[i]} changes predicted quote conversion flag \"\n",
    "                            f\"from {prb_original:.2%} {qcf_original} to {prb:.2%} {qcf}\")\n",
    "                tf = True\n",
    "        return tf\n",
    "\n",
    "    set_sensitive = set()\n",
    "    # Loop through all fields. Check different values of each field to see if result is sensitive to it.\n",
    "    for field in df.columns:\n",
    "        ind = ind_original.copy()\n",
    "        val_original = ind[field]\n",
    "        tf_important = False\n",
    "        num_unique = df[field].nunique()\n",
    "        # If number of unique values is under 30 then try every value (or for objects try every value)\n",
    "        if num_unique < 30 or df.dtypes[field] == 'O':\n",
    "            lst_unique = df[field].unique()\n",
    "            if tf_sensitive(field, val_original, lst_unique, prb_original):\n",
    "                tf_important = True\n",
    "            if tf_important:\n",
    "                logger.info(f\"Possible values of {field} are {lst_unique}\")\n",
    "                set_sensitive.add(field)\n",
    "        else:\n",
    "            if df.dtypes[field] == \"int64\":\n",
    "                vmin = df[field].min()\n",
    "                vmax = df[field].max()\n",
    "                lst_val = [vmin + (vmax - vmin) * i // 10 for i in range(11)]\n",
    "                logger.debug(f\"{field} {num_unique} {df.dtypes[field]!r} {vmin} {vmax} {lst_val}\")\n",
    "                if tf_sensitive(field, val_original, lst_val, prb_original):\n",
    "                    tf_important = True\n",
    "            elif df.dtypes[field] == \"float64\":\n",
    "                vmin = df[field].min()\n",
    "                vmax = df[field].max()\n",
    "                lst_val = [vmin + (vmax - vmin) * i / 10 for i in range(11)]\n",
    "                logger.debug(f\"{field} {num_unique} {df.dtypes[field]!r} {vmin} {vmax} {lst_val}\")\n",
    "                if tf_sensitive(field, val_original, lst_val, prb_original):\n",
    "                    tf_important = True\n",
    "            else:\n",
    "                logger.warning(f\"Unknown type {field} {num_unique} {df.dtypes[field]!r}\")\n",
    "            if tf_important:\n",
    "                set_sensitive.add(field)\n",
    "    # return the set of fields which had individual effects on the prediction\n",
    "    return set_sensitive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606852b",
   "metadata": {},
   "source": [
    "# Application: Step 1 - Ask user for quote number\n",
    "Try quote 325710 for a quote with many fields which could be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a35f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qn_min = sr_conv.index.min()\n",
    "qn_max = sr_conv.index.max()\n",
    "qn = random.randint(qn_min, qn_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c233a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052278f9593249c28b55aebc234b3364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=9049, description='Quote number', layout=Layout(width='800px'), max=434588, min=1, style=Slideâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453a23a3f24740329ec4f328c7fcddfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try 325710 58% 0\n",
    "wdg_quote_success = widgets.Label(value=\"\")\n",
    "def handle_quote_number_change(change):\n",
    "    qn = change.new\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(df.loc[qn])\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    act = sr_conv[qn] if qn in sr_conv else \"unknown\"\n",
    "    wdg_quote_success.value = f\"Quote {change.new} actual {act} predicted {prb:.2%} {qcf}\"\n",
    "style = {'description_width': 'initial', 'width': '500px'}\n",
    "wdg_quote_number = widgets.IntSlider(description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style, layout={'width': '800px'})\n",
    "wdg_quote_number.observe(handle_quote_number_change, names='value')\n",
    "display(wdg_quote_number)\n",
    "display(wdg_quote_success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fd113",
   "metadata": {},
   "source": [
    "# Application: Step 2 - Do sensitivity analysis\n",
    "Normally we would hide the logging output but it helps us playing with data later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb35e5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c97dbc103040938b0d693b24e1d703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#26) ['PersonalField11','CoverageField9','PropertyField37','PersonalField80','SalesField10','PersonalField83','PersonalField4A','PersonalField81','PropertyField39A','PropertyField29'...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = widgets.Output(layout={'border': '1px solid green'})\n",
    "with out:\n",
    "    set_field = sensitivity_analysis(wdg_quote_number.value)\n",
    "display(out)\n",
    "# list of sensitive fields\n",
    "L(set_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c47849",
   "metadata": {},
   "source": [
    "# Application: Step 3 - Try altering values of sensitive fields\n",
    "You can enter more than one to try to improve probability of quote success\n",
    "\n",
    "Example CoverageField9 from E to B and SalesField10 from 0 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc6844fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18e3a517a9a4cfea2f2b5e62f92a47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(RadioButtons(description='PropertyField37', index=1, options=((' ', ' '), ('N', 'N'), ('Y', 'Y'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0b3db2751e4200bd21b145fccaf437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='PersonalField11', options=(('0', 0), ('1', 1), ('2', 2), ('3', 3), ('4', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qn = wdg_quote_number.value\n",
    "lst_dropdown = []\n",
    "lst_radio = []\n",
    "style = {'description_width': 'initial'}\n",
    "def nan_if_nan(n):\n",
    "    \"\"\"Can't include np.nan in dropdowns as np.nan != np.nan. Instead use a str\"\"\"\n",
    "    try:\n",
    "        if np.isnan(n):\n",
    "            return \"nan\"\n",
    "    except TypeError as te:\n",
    "        pass\n",
    "    return n\n",
    "\n",
    "for f in set_field:\n",
    "    num_unique = df[f].nunique()\n",
    "    lst_unique = sorted((str(nan_if_nan(u)), nan_if_nan(u)) for u in df[f].unique())\n",
    "    v = nan_if_nan(df.loc[qn,f])\n",
    "    if num_unique < 5:\n",
    "        wdg = widgets.RadioButtons(options=lst_unique, description=f, style=style, value=v)\n",
    "        lst_radio.append(wdg)\n",
    "    else:\n",
    "        wdg = widgets.Dropdown(options=lst_unique, description=f, style=style, value=v)\n",
    "        lst_dropdown.append(wdg)\n",
    "display(widgets.HBox(children=lst_radio))\n",
    "display(widgets.VBox(children=lst_dropdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f564a2",
   "metadata": {},
   "source": [
    "# Application: Step 4 - Calculate new probability of success\n",
    "Example CoverageField9 from E to B and SalesField10 from 0 to 6\n",
    "\n",
    "Quote went from 58% unsuccessful to 78% successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10c8846b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote 325710 actual unknown predicted 77.76% 1\n"
     ]
    }
   ],
   "source": [
    "qn = wdg_quote_number.value\n",
    "ind = df.loc[qn].copy()\n",
    "for w in lst_radio + lst_dropdown:\n",
    "    if w.value == \"nan\":\n",
    "        v = np.nan\n",
    "    else:\n",
    "        v = w.value\n",
    "    ind[w.description] = v\n",
    "with io.capture_output() as captured:\n",
    "    prd = learn.predict(ind)\n",
    "qcf = prd[1].item()\n",
    "prb = prd[2][qcf].item()\n",
    "act = sr_conv[qn] if qn in sr_conv else \"unknown\"\n",
    "print(f\"Quote {qn} actual {act} predicted {prb:.2%} {qcf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740f496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
