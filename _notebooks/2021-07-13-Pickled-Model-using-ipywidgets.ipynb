{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7e2183",
   "metadata": {},
   "source": [
    "# Pickled Model using ipywidgets\n",
    "> This notebook loads a previously trained model and uses it to predict quote success rate using user input to change fields. User input uses ipywidgets generated on the fly to match allow altering of the most sensitive fields. Final app source code available at [https://github.com/timcu/fast-tabulous-app/blob/main/fast-tabulous-with-db.ipynb](https://github.com/timcu/fast-tabulous-app/blob/main/fast-tabulous-with-db.ipynb) . Final app can be used at [https://tabulous.pythonator.com](https://tabulous.pythonator.com)\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [ipywidgets, TabularLearner, CPU, Sensitivity Analysis]\n",
    "- author: Tim Cummings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "from IPython.display import display\n",
    "from IPython.utils import io  # using io.capture_output\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "logger = logging.getLogger(\"load_pickled_model\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd925f4",
   "metadata": {},
   "source": [
    "## Setup - load trained model\n",
    "On GPU instance run the following command to save TabularLearner\n",
    "\n",
    "    learn.export(fname=\"learn_empty_dls_0708.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/homesite-quote')\n",
    "learn = load_learner(path/\"learn_empty_dls_0708.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79862e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "if not(path/\"homesite-quote-conversion.zip\").exists():\n",
    "    from kaggle import api\n",
    "    api.competition_download_cli('homesite-quote-conversion', path=path)\n",
    "    file_extract(path/\"homesite-quote-conversion.zip\")\n",
    "    file_extract(path/\"train.csv.zip\")\n",
    "    file_extract(path/\"test.csv.zip\")\n",
    "\n",
    "df_train = pd.read_csv(path/'train.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "df_test = pd.read_csv(path/'test.csv', low_memory=False, parse_dates=['Original_Quote_Date'], index_col=\"QuoteNumber\")\n",
    "sr_conv = df_train['QuoteConversion_Flag']\n",
    "df_train.drop('QuoteConversion_Flag', inplace=True, axis=1)\n",
    "df = pd.concat([df_train, df_test])\n",
    "df = add_datepart(df, 'Original_Quote_Date')\n",
    "logger.debug(f\"{df.shape} {df_train.shape} {df_test.shape} {sr_conv.shape}\")\n",
    "df_train = None\n",
    "df_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ca026",
   "metadata": {},
   "source": [
    "## Create a sensitivity analysis tool\n",
    "A field is sensitive if changing the value of the field can change the outcome of the predicted quote success\n",
    "\n",
    "While logging is INFO some logging will occur during a normal run. Setting logging level to WARNING will only log if an unknown dtype is encountered. See setup above to set level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d997bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "def sensitivity_analysis(qn):\n",
    "    \"\"\"Using data from quote number qn do a sensitivity analysis on all independent variables\"\"\"\n",
    "    time_start = datetime.now()\n",
    "    # Independent variables\n",
    "    ind_original = df.loc[qn]\n",
    "    prd = learn.predict(ind_original)\n",
    "    # Predicted quote conversion flag\n",
    "    qcf_original = prd[1].item()\n",
    "    # Probability that quote conversion flag is as predicted\n",
    "    prb_original = prd[2][qcf_original].item()\n",
    "    logger.info(f\"Sensitivity Analysis for Quote {qn}\")\n",
    "    # Check if we actually know the correct answer\n",
    "    if qn in sr_conv.index:\n",
    "        logger.info(f\"Actual QuoteConversion_Flag {sr_conv[qn]}\")\n",
    "\n",
    "    def tf_sensitive(f, v_original, lst_v, p_original):\n",
    "        \"\"\"predicts quote success after changing field f from v_original to each value in lst_v. \n",
    "        If prediction changes then quote is sensitive to the value of this field and True is returned\"\"\"\n",
    "        # Create a DataFrame which has every row identical except for field in question\n",
    "        # Field f iterates through every value provided\n",
    "        ind_other = df.loc[qn:qn].copy().drop(f, axis=1)  # fields other than f\n",
    "        ind_f = pd.DataFrame(data={f: lst_v}, index=[qn] * len(lst_v))\n",
    "        # Merge these two DataFrames to create one with all rows identical except field f\n",
    "        ind = pd.merge(ind_other, ind_f, right_index=True, left_index=True)\n",
    "        # Copy lines from learn.predict() because we want to predict several rows at once (faster than one at a time)\n",
    "        dl = learn.dls.test_dl(ind)\n",
    "        dl.dataset.conts = dl.dataset.conts.astype(np.float32)\n",
    "        # stop learn.get_preds() printing blank lines\n",
    "        with io.capture_output() as captured:\n",
    "            # using get_preds() rather than predict() because get_preds can do multiple rows at once\n",
    "            inp,preds,_,dec_preds = learn.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "        tf = False\n",
    "        # Check if any predictions changed\n",
    "        for i, dp in enumerate(dec_preds):\n",
    "            qcf = dp.item()\n",
    "            if qcf != qcf_original:\n",
    "                prb = preds[i][qcf].item()\n",
    "                logger.info(f\"Changing {f} from {val_original} to {lst_v[i]} changes prediction \"\n",
    "                            f\"from {prb_original:.2%} {qcf_original} to {prb:.2%} {qcf}\")\n",
    "                tf = True\n",
    "        return tf\n",
    "\n",
    "    set_sensitive = set()\n",
    "    # Loop through all fields. Check different values of each field to see if result is sensitive to it.\n",
    "    for field in df.columns:\n",
    "        ind = ind_original.copy()\n",
    "        val_original = ind[field]\n",
    "        tf_important = False\n",
    "        num_unique = df[field].nunique()\n",
    "        # If number of unique values is under 30 then try every value (or for objects try every value)\n",
    "        if num_unique < 30 or df.dtypes[field] == 'O':\n",
    "            lst_unique = df[field].unique()\n",
    "            if tf_sensitive(field, val_original, lst_unique, prb_original):\n",
    "                tf_important = True\n",
    "            if tf_important:\n",
    "                logger.info(f\"Possible values of {field} are {lst_unique}\")\n",
    "                set_sensitive.add(field)\n",
    "        else:\n",
    "            if df.dtypes[field] == \"int64\":\n",
    "                vmin = df[field].min()\n",
    "                vmax = df[field].max()\n",
    "                lst_val = [vmin + (vmax - vmin) * i // 10 for i in range(11)]\n",
    "                logger.debug(f\"{field} {num_unique} {df.dtypes[field]!r} {vmin} {vmax} {lst_val}\")\n",
    "                if tf_sensitive(field, val_original, lst_val, prb_original):\n",
    "                    tf_important = True\n",
    "            elif df.dtypes[field] == \"float64\":\n",
    "                vmin = df[field].min()\n",
    "                vmax = df[field].max()\n",
    "                lst_val = [vmin + (vmax - vmin) * i / 10 for i in range(11)]\n",
    "                logger.debug(f\"{field} {num_unique} {df.dtypes[field]!r} {vmin} {vmax} {lst_val}\")\n",
    "                if tf_sensitive(field, val_original, lst_val, prb_original):\n",
    "                    tf_important = True\n",
    "            else:\n",
    "                logger.warning(f\"Unknown type {field} {num_unique} {df.dtypes[field]!r}\")\n",
    "            if tf_important:\n",
    "                set_sensitive.add(field)\n",
    "        # return the set of fields which had individual effects on the prediction\n",
    "    logger.info(f\"Time taken = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    return set_sensitive\n",
    "\n",
    "def lst_ind_value(df, field):\n",
    "    \"\"\"Return the list of independent values to be tested for field\"\"\"\n",
    "    num_unique = df[field].nunique()\n",
    "    # If number of unique values is under 30 then try every value (or for objects try every value)\n",
    "    if num_unique < 30 or df.dtypes[field] == 'O':\n",
    "        return df[field].unique()\n",
    "    else:\n",
    "        if df.dtypes[field] == \"int64\":\n",
    "            vmin = df[field].min()\n",
    "            vmax = df[field].max()\n",
    "            return [vmin + (vmax - vmin) * i // 10 for i in range(11)]\n",
    "        elif df.dtypes[field] == \"float64\":\n",
    "            vmin = df[field].min()\n",
    "            vmax = df[field].max()\n",
    "            return [vmin + (vmax - vmin) * i / 10 for i in range(11)]\n",
    "        else:\n",
    "            logger.warning(f\"Unknown type {field} {num_unique} {df.dtypes[field]!r}\")\n",
    "            return []\n",
    "\n",
    "def tf_equal_or_nan(a, b):\n",
    "    if a == b:\n",
    "        return True\n",
    "    try:\n",
    "        if np.isnan(a) and np.isnan(b):\n",
    "            return True\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return False\n",
    "        \n",
    "def df_for_field(qn, df, f, lst_v):\n",
    "    \"\"\"predicts quote success after changing field f from v_original to each value in lst_v.\n",
    "    If prediction changes then quote is sensitive to the value of this field and True is returned\n",
    "    Keyword arguments\n",
    "        qn: quote number \n",
    "        df: dataframe of quote independent values\n",
    "        f: field name\n",
    "        lst_v: list of alternative values of independent value in field f\n",
    "    Returns\n",
    "        dataframe of alternative values in field f and all other fields staying the same and a column called fieldname\n",
    "    \"\"\"\n",
    "    # Create a DataFrame which has every row identical except for field in question\n",
    "    # Field f iterates through every value provided\n",
    "    ind_other = df.loc[qn:qn].copy().drop(f, axis=1)  # fields other than f\n",
    "    ind_f = pd.DataFrame(data={f: lst_v, \"fieldname\": [f] * len(lst_v)}, index=[qn] * len(lst_v))\n",
    "    # Merge these two DataFrames to create one with all rows identical except field f\n",
    "    return pd.merge(ind_other, ind_f, right_index=True, left_index=True)\n",
    "\n",
    "def sensitivity_analysis(qn):\n",
    "    \"\"\"Using data from quote number qn do a sensitivity analysis on all independent variables\"\"\"\n",
    "    time_start = datetime.now()\n",
    "    # Independent variables\n",
    "    ind_original = df.loc[qn]\n",
    "    prd = learn.predict(ind_original)\n",
    "    # Predicted quote conversion flag\n",
    "    qcf_original = prd[1].item()\n",
    "    # Probability that quote conversion flag is as predicted\n",
    "    prb_original = prd[2][qcf_original].item()\n",
    "    logger.info(f\"Sensitivity Analysis for Quote {qn}\")\n",
    "    # Check if we actually know the correct answer\n",
    "    if qn in sr_conv.index:\n",
    "        logger.info(f\"Actual QuoteConversion_Flag {sr_conv[qn]}\")\n",
    "\n",
    "    lst_df_for_field = []\n",
    "    # Loop through all fields. Check different values of each field to see if result is sensitive to it.\n",
    "    for field in df.columns:\n",
    "        ind = ind_original.copy()\n",
    "        val_original = ind[field]\n",
    "        lst_val = lst_ind_value(df, field)\n",
    "        lst_df_for_field.append(df_for_field(qn, df, field, lst_val))\n",
    "    df_sensitivity = pd.concat(lst_df_for_field, ignore_index=True)\n",
    "    sr_fieldname = df_sensitivity['fieldname']\n",
    "    df_sensitivity.drop('fieldname', inplace=True, axis=1)\n",
    "    dl = learn.dls.test_dl(df_sensitivity)\n",
    "    dl.dataset.conts = dl.dataset.conts.astype(np.float32)\n",
    "    # stop learn.get_preds() printing blank lines\n",
    "    with io.capture_output() as captured:\n",
    "        # using get_preds() rather than predict() because get_preds can do multiple rows at once\n",
    "        inp,preds,_,dec_preds = learn.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "    logger.info(f\"Time taken = {(datetime.now() - time_start).total_seconds()} seconds\")\n",
    "    df_results=pd.DataFrame({'fieldname': sr_fieldname, 'prob_success': preds[:,1]})\n",
    "    df_results.sort_values(by='prob_success', ascending=False, inplace=True)\n",
    "    return df_results, df_sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606852b",
   "metadata": {},
   "source": [
    "# Application: Step 1 - Ask user for quote number\n",
    "Try quote 325710 for a quote with many fields which could be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c233a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "qn_min = sr_conv.index.min()\n",
    "qn_max = sr_conv.index.max()\n",
    "qn = random.randint(qn_min, qn_max)\n",
    "\n",
    "wdg_quote_success = widgets.Label(value=\"\")\n",
    "def handle_quote_number_change(change):\n",
    "    global qn\n",
    "    qn = change.new\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(df.loc[qn])\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    act = sr_conv[qn] if qn in sr_conv else \"unknown\"\n",
    "    wdg_quote_success.value = f\"Quote {change.new} actual {act} predicted {prb:.2%} {qcf}\"\n",
    "style = {'description_width': 'initial', 'width': '500px'}\n",
    "wdg_quote_number_text = widgets.BoundedIntText(description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style)\n",
    "wdg_quote_number_slider = widgets.IntSlider(description=\"Quote number\", min=qn_min, max=qn_max, value=qn, style=style, layout={'width': '600px'})\n",
    "mylink = widgets.jslink((wdg_quote_number_text, 'value'), (wdg_quote_number_slider, 'value'))\n",
    "wdg_quote_number_slider.observe(handle_quote_number_change, names='value')\n",
    "display(wdg_quote_number_text)\n",
    "display(wdg_quote_number_slider)\n",
    "display(wdg_quote_success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8338c00",
   "metadata": {},
   "source": [
    "![](images/post0713_quote_input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fd113",
   "metadata": {},
   "source": [
    "# Application: Step 2 - Do sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb35e5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fieldname</th>\n",
       "      <th>prob_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>PropertyField29</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>PropertyField37</td>\n",
       "      <td>0.999607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>PersonalField2</td>\n",
       "      <td>0.991576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>PersonalField84</td>\n",
       "      <td>0.991404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>PersonalField13</td>\n",
       "      <td>0.990831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.982206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.976485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.969538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.964867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>PropertyField37</td>\n",
       "      <td>0.960644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.948517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.937945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.869847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.848974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.821979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>PersonalField12</td>\n",
       "      <td>0.821645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.818617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.806710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>PersonalField27</td>\n",
       "      <td>0.779141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>PersonalField13</td>\n",
       "      <td>0.765224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fieldname  prob_success\n",
       "2084  PropertyField29      1.000000\n",
       "2109  PropertyField37      0.999607\n",
       "627    PersonalField2      0.991576\n",
       "1629  PersonalField84      0.991404\n",
       "765   PersonalField13      0.990831\n",
       "1112  PersonalField27      0.982206\n",
       "1114  PersonalField27      0.976485\n",
       "1113  PersonalField27      0.969538\n",
       "1117  PersonalField27      0.964867\n",
       "2110  PropertyField37      0.960644\n",
       "1115  PersonalField27      0.948517\n",
       "1119  PersonalField27      0.937945\n",
       "1118  PersonalField27      0.869847\n",
       "1120  PersonalField27      0.848974\n",
       "1125  PersonalField27      0.821979\n",
       "762   PersonalField12      0.821645\n",
       "1121  PersonalField27      0.818617\n",
       "1116  PersonalField27      0.806710\n",
       "1123  PersonalField27      0.779141\n",
       "766   PersonalField13      0.765224"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse\n",
    "out = widgets.Output(layout={'border': '1px solid green'})\n",
    "with out:\n",
    "    df_results, df_sensitivity = sensitivity_analysis(wdg_quote_number_slider.value)\n",
    "# display(out)\n",
    "df_results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c47849",
   "metadata": {},
   "source": [
    "# Application: Step 3 - Try altering values of sensitive fields\n",
    "You can enter more than one to try to improve probability of quote success\n",
    "\n",
    "Example CoverageField9 from E to B and SalesField10 from 0 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f2bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "wdg_status = widgets.HTML(value=f\"<h2>Quote {qn}</h2>\")\n",
    "\n",
    "def handle_input_change(change):\n",
    "    qn = wdg_quote_number_slider.value\n",
    "    ind = df.loc[qn].copy()\n",
    "    for w in lst_input:\n",
    "        if w.value == \"nan\":\n",
    "            v = np.nan\n",
    "        else:\n",
    "            v = w.value\n",
    "        print(qn, w.description, v)\n",
    "        ind[w.description] = v\n",
    "    with io.capture_output() as captured:\n",
    "        prd = learn.predict(ind)\n",
    "    print(prd[1], prd[2])\n",
    "    qcf = prd[1].item()\n",
    "    prb = prd[2][qcf].item()\n",
    "    act = sr_conv[qn] if qn in sr_conv else \"unknown\"\n",
    "    wdg_status.value = f\"<h2>Quote {qn} actual {act} predicted {prb:.2%} {qcf}</h2>\"\n",
    "\n",
    "display(wdg_status)\n",
    "qn = wdg_quote_number_slider.value\n",
    "style = {'description_width': 'initial'}\n",
    "def nan_if_nan(n):\n",
    "    \"\"\"Can't include np.nan in dropdowns as np.nan != np.nan. Instead use a str\"\"\"\n",
    "    try:\n",
    "        if np.isnan(n):\n",
    "            return \"nan\"\n",
    "    except TypeError as te:\n",
    "        pass\n",
    "    return n\n",
    "\n",
    "i = 0\n",
    "dct_fields = defaultdict(list)\n",
    "while len(dct_fields.keys()) < 10 and i < df.shape[1]:\n",
    "    f = df_results.iloc[i, 0]  # fieldname column\n",
    "    idx = df_results.index[i]\n",
    "    ind_val = df_sensitivity.loc[idx, f]\n",
    "    dct_fields[f].append(ind_val)\n",
    "    i += 1\n",
    "priority = 0\n",
    "lst_input = []\n",
    "for f, lst_recommend in dct_fields.items():\n",
    "    priority += 1\n",
    "    num_unique = df[f].nunique()\n",
    "    lst_unique = sorted((str(nan_if_nan(u)), nan_if_nan(u)) for u in df[f].unique())\n",
    "    v = nan_if_nan(df.loc[qn,f])\n",
    "    tip = f\"Priority {priority}. Initially {v}. Recommend {lst_recommend}\"\n",
    "    lbl = widgets.HTML(value=f\"{tip}\")\n",
    "    if num_unique < 5 and len(lst_unique) < 4:\n",
    "        wdg = widgets.RadioButtons(options=lst_unique, \n",
    "                                   description=f, \n",
    "                                   description_tooltip=tip,\n",
    "                                   style=style, \n",
    "                                   value=v)\n",
    "    else:\n",
    "        wdg = widgets.Dropdown(options=lst_unique, \n",
    "                               description=f, \n",
    "                               description_tooltip=tip,\n",
    "                               style=style, \n",
    "                               value=v)\n",
    "    wdg.observe(handle_input_change, names='value')\n",
    "    display(widgets.HBox(children=[wdg, lbl]))\n",
    "    lst_input.append(wdg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c0df0",
   "metadata": {},
   "source": [
    "![](images/post0713_lst_input.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df0451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
