{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2020-07-02-Finding-Optimum-XGBoost-Parameters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "365551fa-4973-48d4-be68-1227dddd1669"
      },
      "source": [
        "# Finding Optimum XGBoost Parameters for Tabular For Homesite Competition\n",
        "> Building on the work of the previous notebook, which referenced [Zach's notebook](https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Tabular%20Notebooks/02_Ensembling.ipynb) to apply his techniques for permutation importance and ensemble learning to the Homesite Competition problem set, we will deep dive into optimizing the XGBoost parameters to see if an improved model can be generated, and what effect this has for our resulting ensemble model's predictions\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [kaggle, fastai]\n",
        "- author: Nissan Dookeran\n",
        "- image: images/chart-preview.png"
      ],
      "id": "365551fa-4973-48d4-be68-1227dddd1669"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc1f57d1-29fb-421b-aef5-def71857c4fa"
      },
      "source": [
        "## Introduction\n",
        "Using the [code here](https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/) we will look at the optimal number of estimators, depth, and then combination of the two when using XGBoost to generate a model\n",
        "\n",
        "Notes:\n",
        "- Possible improvements if manually coding would be to add `subsamples` as a variable, however with both the increase of permutations and the long running times for GridSearch and a look to explore other options like Optuna and Bayesian Search to automate this, I limited it to just `max_depth` and `learning_rate` as the additional variables for now\n",
        "- Because of timeouts for long ranges, broke up the ranges for the various parameters into groupings, will only explore a subsequent grouping if there is an optimal value that is max in a previous grouping. This will also give a more manageable range for the permutations when trying to find the best combination of all parameters \n",
        "- Added to tune learning_rate based on [this code](https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/)\n",
        "- Removed the `triage` variable, `FillMissing` will handle NA values in categorical fields appropriately, but just need to filter it out from modifying categories function\n",
        "- Changed the categorize functions from [last notebook](https://redditech.github.io/team-fast-tabulous/kaggle/fastai/2021/06/27/Improving-Fastai-split-choices.html) to exclude any columns in y_names from being evaluated since these shouldn't be part of the model training as a parameter\n",
        "- Added code to save all models to reuse in another notebook that submits to Kaggle for test evaluation"
      ],
      "id": "bc1f57d1-29fb-421b-aef5-def71857c4fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6651bcd-4e16-461c-ad9f-8e14aca0f164"
      },
      "source": [
        "## Setup"
      ],
      "id": "e6651bcd-4e16-461c-ad9f-8e14aca0f164"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaa7ZAV41err"
      },
      "source": [
        ">> Adding based on [tutorial](https://github.com/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb) for notebooks"
      ],
      "id": "Eaa7ZAV41err"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-9f1Ear1cWw",
        "outputId": "674627d3-392e-4afd-98f8-831146a73d45"
      },
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "!pip install -Uqq fastai\n",
        "!pip install kaggle\n",
        "from fastai.tabular.all import *"
      ],
      "id": "l-9f1Ear1cWw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 194kB 14.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-of_3lHmASEN",
        "outputId": "9cd60712-0b0f-4878-8046-6125a7fc7e45"
      },
      "source": [
        "global gdrive #colab only code block\n",
        "gdrive = Path('/content/gdrive/My Drive')\n",
        "from google.colab import drive\n",
        "if not gdrive.exists(): drive.mount(str(gdrive.parent))\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/gdrive/MyDrive/Kaggle/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "id": "-of_3lHmASEN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1884b0f7-7cae-4d51-9885-d83388ff7471",
        "outputId": "c5131ef6-4984-4dac-b71c-1da2fa24bddf"
      },
      "source": [
        "from kaggle import api\n",
        "path = Path.cwd()\n",
        "path.ls()"
      ],
      "id": "1884b0f7-7cae-4d51-9885-d83388ff7471",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('/content/.config'),Path('/content/gdrive'),Path('/content/sample_data')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37f02749-f62f-4597-8133-57cfb1f9d0e7"
      },
      "source": [
        "> Only run the next three lines the first time if in a local repository. This will prevent large training data files and model files being checked into Github"
      ],
      "id": "37f02749-f62f-4597-8133-57cfb1f9d0e7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c92a1495-ba58-44bd-9145-52c78dde1fdc"
      },
      "source": [
        "!touch .gitignore"
      ],
      "id": "c92a1495-ba58-44bd-9145-52c78dde1fdc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44693a7f-2a48-4ed5-8cbd-44b2ea4a771c"
      },
      "source": [
        "!echo \"_data\" > .gitignore"
      ],
      "id": "44693a7f-2a48-4ed5-8cbd-44b2ea4a771c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0480c25d-b21f-43e0-bdb8-355cbe58f3f0"
      },
      "source": [
        "!mkdir _data"
      ],
      "id": "0480c25d-b21f-43e0-bdb8-355cbe58f3f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8abd520-fbc2-4c2e-a7c9-bfcdc2822a34",
        "outputId": "41ee952b-1118-454b-b34c-69bd5fc18d12"
      },
      "source": [
        "os.chdir('_data')\n",
        "Path.cwd()"
      ],
      "id": "d8abd520-fbc2-4c2e-a7c9-bfcdc2822a34",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/_data')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3a9675-1264-4115-9c1e-19aecf133806"
      },
      "source": [
        "> Back to it"
      ],
      "id": "dd3a9675-1264-4115-9c1e-19aecf133806"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFLLH-p2CTT_",
        "outputId": "c0f801e7-ffb9-4776-c471-4ad2200a4669"
      },
      "source": [
        "os.chdir(path/\"gdrive/MyDrive/Kaggle/\") # colab only code\n",
        "Path.cwd()"
      ],
      "id": "DFLLH-p2CTT_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/gdrive/MyDrive/Kaggle')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e82921f-d0e6-43a9-b88a-75617e2247df",
        "outputId": "d2806508-67a5-44a8-d9b9-289f8f723278"
      },
      "source": [
        "path = Path.cwd()/\"homesite_competition_data\"\n",
        "path.mkdir(exist_ok=True)\n",
        "Path.BASE_PATH = path\n",
        "api.competition_download_cli('homesite-quote-conversion', path=path)\n",
        "file_extract(path/\"homesite-quote-conversion.zip\")\n",
        "file_extract(path/\"train.csv.zip\")\n",
        "file_extract(path/\"test.csv.zip\")\n",
        "path.ls()"
      ],
      "id": "7e82921f-d0e6-43a9-b88a-75617e2247df",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "homesite-quote-conversion.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6) [Path('homesite-quote-conversion.zip'),Path('sample_submission.csv.zip'),Path('test.csv.zip'),Path('train.csv.zip'),Path('train.csv'),Path('test.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a38ab884-7034-438f-aa47-8c86889b44eb"
      },
      "source": [
        "Settings"
      ],
      "id": "a38ab884-7034-438f-aa47-8c86889b44eb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b9da21b-39d6-4e2e-ba2b-1b5c463e8481"
      },
      "source": [
        "test_size = 0.3\n",
        "y_block=CategoryBlock()\n",
        "# n_estimators = [50, 100, 150, 200]\n",
        "# max_depth = [2, 4, 6, 8]\n",
        "n_estimators_range = range(50,500,50)\n",
        "n_estimators_range1 = range(500,1050,50)\n",
        "n_estimators_range2 = range(1050,1500,50)\n",
        "n_estimators_range3 = range(1550,2050,50)\n",
        "max_depth_range = range(1, 12, 2)\n",
        "max_depth_range1 = range(13,22,2)\n",
        "max_depth_range2 = range(23,32,2)\n",
        "learning_rate_range = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "subsample_range = [0.1,0.3,0.5,0.7,1.0]\n",
        "sampling_methods = ['uniform','gradient_based']\n",
        "random_seed =42\n",
        "n_splits = 10 # 10 folds\n",
        "scoring = \"roc_auc\"\n",
        "category_threshold = 20"
      ],
      "id": "4b9da21b-39d6-4e2e-ba2b-1b5c463e8481",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-NxoxFyGCyi"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "# valid_score = roc_auc_score(to_np(targs), to_np(preds[:,1]))\n",
        "# valid_score"
      ],
      "id": "q-NxoxFyGCyi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaBL3Oe3-olm"
      },
      "source": [
        "## The [GridsearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) functions"
      ],
      "id": "GaBL3Oe3-olm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2660e8e-7c8e-4afe-a65f-6e8a770ccec0"
      },
      "source": [
        "Customising functions from [this page](https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/) and [this page](https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/)to work with our dataset"
      ],
      "id": "b2660e8e-7c8e-4afe-a65f-6e8a770ccec0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7587901a-c22d-4af0-832b-8aa86666bb2b"
      },
      "source": [
        "import xgboost as xgb\n",
        "import matplotlib\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from matplotlib import pyplot"
      ],
      "id": "7587901a-c22d-4af0-832b-8aa86666bb2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6466783e-1675-4f74-b6a3-0706f8f035c5"
      },
      "source": [
        "This function will tune for `n_estimators` only\n",
        "\n",
        "**Notes**\n",
        "- Used https://scikit-learn.org/stable/modules/model_evaluation.html#scoring to find correct `scoring` string\n",
        "- Reading more on [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) to understand if I used the `n_splits` correctly, I chose 10 based on [this article](https://machinelearningmastery.com/k-fold-cross-validation/)"
      ],
      "id": "6466783e-1675-4f74-b6a3-0706f8f035c5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ae48f62-7c80-497b-96e8-e6d59412d27d"
      },
      "source": [
        "# XGBoost, Tune n_estimators\n",
        "\n",
        "def xgboost_tune_estimators(X, y, n_estimators_range, n_splits, sampling_methods, random_seed, scoring):\n",
        "    matplotlib.use('Agg')\n",
        "    label_encoded_y = LabelEncoder().fit_transform(y)\n",
        "    # grid search\n",
        "    model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0, verbosity=2, sampling_methods=sampling_methods)\n",
        "    param_grid = dict(n_estimators=n_estimators_range)\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring=scoring, n_jobs=-1, cv=kfold, verbose=4)\n",
        "    grid_result = grid_search.fit(X, label_encoded_y)\n",
        "    # summarize results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    # plot\n",
        "    pyplot.errorbar(n_estimators_range, means, yerr=stds)\n",
        "    pyplot.title(\"XGBoost n_estimators vs Log Loss\")\n",
        "    pyplot.xlabel('n_estimators')\n",
        "    pyplot.ylabel('Log Loss')\n",
        "    pyplot.savefig('n_estimators.png')"
      ],
      "id": "7ae48f62-7c80-497b-96e8-e6d59412d27d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c6b6879-d795-4e27-a67d-a66d2c203d54"
      },
      "source": [
        "This function will tune for `max_depth` value only"
      ],
      "id": "2c6b6879-d795-4e27-a67d-a66d2c203d54"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "212b7cec-9de5-4e9a-8a15-605331f31a70"
      },
      "source": [
        "# XGBoost, Tune max_depth\n",
        "def xgboost_tune_max_depth(X,y, max_depth_range, n_splits, sampling_methods, random_seed, scoring):\n",
        "    matplotlib.use('Agg')\n",
        "    # encode string class values as integers\n",
        "    label_encoded_y = LabelEncoder().fit_transform(y)\n",
        "    # grid search\n",
        "    model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0, verbosity=2, sampling_methods=sampling_methods)\n",
        "    print(max_depth_range)\n",
        "    param_grid = dict(max_depth=max_depth_range)\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring=scoring, n_jobs=-1, cv=kfold, verbose=4)\n",
        "    grid_result = grid_search.fit(X, label_encoded_y)\n",
        "    # summarize results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    # plot\n",
        "    pyplot.errorbar(max_depth_range, means, yerr=stds)\n",
        "    pyplot.title(\"XGBoost max_depth vs Log Loss\")\n",
        "    pyplot.xlabel('max_depth')\n",
        "    pyplot.ylabel('Log Loss')\n",
        "    pyplot.savefig('max_depth.png')"
      ],
      "id": "212b7cec-9de5-4e9a-8a15-605331f31a70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeoVPR4IbsY7"
      },
      "source": [
        "This function will tune for `learning_rate`"
      ],
      "id": "QeoVPR4IbsY7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DUY0FdfbsxK"
      },
      "source": [
        "def xgboost_tune_lr(X, y, lr_range, n_splits, sampling_methods, random_seed, scoring):\n",
        "    matplotlib.use('Agg')\n",
        "    label_encoded_y = LabelEncoder().fit_transform(y)\n",
        "    # grid search\n",
        "    model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0, verbosity=2, sampling_methods=sampling_methods)\n",
        "    param_grid = dict(learning_rate=lr_range)\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring=scoring, n_jobs=-1, cv=kfold, verbose=4)\n",
        "    grid_result = grid_search.fit(X, label_encoded_y)\n",
        "    # summarize results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    # plot\n",
        "    pyplot.errorbar(lr_range, means, yerr=stds)\n",
        "    pyplot.title(\"XGBoost learning_rate vs Log Loss\")\n",
        "    pyplot.xlabel('learning_rate')\n",
        "    pyplot.ylabel('Log Loss')\n",
        "    pyplot.savefig('learning_rate.png')"
      ],
      "id": "6DUY0FdfbsxK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efab18b3-2e32-4c8f-98bc-001adf80c6ab"
      },
      "source": [
        "This function will tune for `n_estimators`, `max_depth`, `learning_rate` in combination (takes really long to run)"
      ],
      "id": "efab18b3-2e32-4c8f-98bc-001adf80c6ab"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e200d154-d4f2-4aa2-87f3-c03ca39f35aa"
      },
      "source": [
        "# XGBoost, Tune n_estimators, max_depth, learning_rate\n",
        "def xgboost_tune_n_estimators_and_max_depth_and_lr(X, y, n_estimators_range, max_depth_range, lr_range, n_splits, sampling_methods, random_seed, scoring):\n",
        "    matplotlib.use('Agg')\n",
        "    # encode string class values as integers\n",
        "    label_encoded_y = LabelEncoder().fit_transform(y)\n",
        "    # grid search\n",
        "    model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0, verbosity=2, sampling_methods=sampling_methods)\n",
        "    print(n_estimators_range)\n",
        "    print(max_depth_range)\n",
        "    print(lr_range)\n",
        "    param_grid = dict(max_depth=max_depth_range, n_estimators=n_estimators_range, learning_rate=lr_range)\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring=scoring, n_jobs=-1, cv=kfold, verbose=4)\n",
        "    grid_result = grid_search.fit(X, label_encoded_y)\n",
        "    # summarize results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    # plot results\n",
        "    # scores = np.array(means).reshape(len(max_depth_range), len(n_estimators_range))\n",
        "    # for i, value in enumerate(max_depth_range):\n",
        "    #   pyplot.plot(n_estimators_range, scores[i], label='depth: ' + str(value))\n",
        "    # pyplot.legend()\n",
        "    # pyplot.xlabel('n_estimators')\n",
        "    # pyplot.ylabel('Log Loss')\n",
        "    # pyplot.savefig('n_estimators_vs_max_depth.png')"
      ],
      "id": "e200d154-d4f2-4aa2-87f3-c03ca39f35aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c1c9dd6-9a9d-4ace-a29e-2a42b79146fe"
      },
      "source": [
        "### My useful functions"
      ],
      "id": "2c1c9dd6-9a9d-4ace-a29e-2a42b79146fe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4020a287-f9c6-4573-be77-216ffe5ae104"
      },
      "source": [
        "def reassign_to_categorical(field, df, y_names, continuous, categorical):\n",
        "  if ((df[field].isna().sum()==0) and (field not in y_names)):\n",
        "    field_categories = df[field].unique()\n",
        "    df[field] = df[field].astype('category')\n",
        "    df[field].cat.set_categories(field_categories, inplace=True)\n",
        "    if field in continuous: continuous.remove(field)\n",
        "    if field not in categorical: categorical.append(field)\n",
        "\n",
        "  return df, continuous, categorical"
      ],
      "id": "4020a287-f9c6-4573-be77-216ffe5ae104",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cd5ea65-57a1-410e-879b-f8992b97529c"
      },
      "source": [
        "def categorize( df, y_names, cont_names, cat_names, category_threshold=50):\n",
        "  for field in df.columns:\n",
        "    if ((len(df[field].unique()) <= category_threshold) and (type(df[field].dtype) != pd.core.dtypes.dtypes.CategoricalDtype)):\n",
        "      reassign_to_categorical(field, df, y_names, cont_names, cat_names)\n",
        "  return df, cont_names, cat_names"
      ],
      "id": "6cd5ea65-57a1-410e-879b-f8992b97529c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "746861ca-eb5d-4697-9597-f423b724e62a"
      },
      "source": [
        "def homesite_prep(df_train, df_test, y_names, category_threshold):\n",
        "    df_train.QuoteConversion_Flag = df_train.QuoteConversion_Flag.astype(dtype='boolean')\n",
        "    df_train = df_train.set_index('QuoteNumber')\n",
        "    df_test = df_test.set_index('QuoteNumber')\n",
        "    df_train['Original_Quote_Date'] = pd.to_datetime(df_train['Original_Quote_Date'])\n",
        "    df_test['Original_Quote_Date'] = pd.to_datetime(df_test['Original_Quote_Date'])\n",
        "    df_train = add_datepart(df_train, 'Original_Quote_Date')\n",
        "    df_test = add_datepart(df_test, 'Original_Quote_Date')\n",
        "    cont_names, cat_names = cont_cat_split(df_train, dep_var=y_names)\n",
        "    df_train, cont_names, cat_names = categorize(df_train, y_names, cont_names, cat_names, category_threshold)\n",
        "    return df_train, df_test, cont_names, cat_names"
      ],
      "id": "746861ca-eb5d-4697-9597-f423b724e62a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8bb0182-38db-4480-b157-4d3f65ac66a3"
      },
      "source": [
        "def find_y_columns(df_train, df_test):\n",
        "    y_columns = df_train.columns.difference(df_test.columns)\n",
        "    return y_columns"
      ],
      "id": "f8bb0182-38db-4480-b157-4d3f65ac66a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecc5c275-4893-4af5-ab13-6a28e3f2b93a"
      },
      "source": [
        "### Load the data"
      ],
      "id": "ecc5c275-4893-4af5-ab13-6a28e3f2b93a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "9d191131-6d37-43c3-ac1f-9d5ea4aa8a11",
        "outputId": "f4fa0b60-bb99-481b-b438-ad529ebc2b23"
      },
      "source": [
        "df_train = pd.read_csv(path/\"train.csv\", low_memory=False)\n",
        "df_train.head(2)"
      ],
      "id": "9d191131-6d37-43c3-ac1f-9d5ea4aa8a11",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QuoteNumber</th>\n",
              "      <th>Original_Quote_Date</th>\n",
              "      <th>QuoteConversion_Flag</th>\n",
              "      <th>Field6</th>\n",
              "      <th>Field7</th>\n",
              "      <th>Field8</th>\n",
              "      <th>Field9</th>\n",
              "      <th>Field10</th>\n",
              "      <th>Field11</th>\n",
              "      <th>Field12</th>\n",
              "      <th>CoverageField1A</th>\n",
              "      <th>CoverageField1B</th>\n",
              "      <th>CoverageField2A</th>\n",
              "      <th>CoverageField2B</th>\n",
              "      <th>CoverageField3A</th>\n",
              "      <th>CoverageField3B</th>\n",
              "      <th>CoverageField4A</th>\n",
              "      <th>CoverageField4B</th>\n",
              "      <th>CoverageField5A</th>\n",
              "      <th>CoverageField5B</th>\n",
              "      <th>CoverageField6A</th>\n",
              "      <th>CoverageField6B</th>\n",
              "      <th>CoverageField8</th>\n",
              "      <th>CoverageField9</th>\n",
              "      <th>CoverageField11A</th>\n",
              "      <th>CoverageField11B</th>\n",
              "      <th>SalesField1A</th>\n",
              "      <th>SalesField1B</th>\n",
              "      <th>SalesField2A</th>\n",
              "      <th>SalesField2B</th>\n",
              "      <th>SalesField3</th>\n",
              "      <th>SalesField4</th>\n",
              "      <th>SalesField5</th>\n",
              "      <th>SalesField6</th>\n",
              "      <th>SalesField7</th>\n",
              "      <th>SalesField8</th>\n",
              "      <th>SalesField9</th>\n",
              "      <th>SalesField10</th>\n",
              "      <th>SalesField11</th>\n",
              "      <th>SalesField12</th>\n",
              "      <th>...</th>\n",
              "      <th>GeographicField44A</th>\n",
              "      <th>GeographicField44B</th>\n",
              "      <th>GeographicField45A</th>\n",
              "      <th>GeographicField45B</th>\n",
              "      <th>GeographicField46A</th>\n",
              "      <th>GeographicField46B</th>\n",
              "      <th>GeographicField47A</th>\n",
              "      <th>GeographicField47B</th>\n",
              "      <th>GeographicField48A</th>\n",
              "      <th>GeographicField48B</th>\n",
              "      <th>GeographicField49A</th>\n",
              "      <th>GeographicField49B</th>\n",
              "      <th>GeographicField50A</th>\n",
              "      <th>GeographicField50B</th>\n",
              "      <th>GeographicField51A</th>\n",
              "      <th>GeographicField51B</th>\n",
              "      <th>GeographicField52A</th>\n",
              "      <th>GeographicField52B</th>\n",
              "      <th>GeographicField53A</th>\n",
              "      <th>GeographicField53B</th>\n",
              "      <th>GeographicField54A</th>\n",
              "      <th>GeographicField54B</th>\n",
              "      <th>GeographicField55A</th>\n",
              "      <th>GeographicField55B</th>\n",
              "      <th>GeographicField56A</th>\n",
              "      <th>GeographicField56B</th>\n",
              "      <th>GeographicField57A</th>\n",
              "      <th>GeographicField57B</th>\n",
              "      <th>GeographicField58A</th>\n",
              "      <th>GeographicField58B</th>\n",
              "      <th>GeographicField59A</th>\n",
              "      <th>GeographicField59B</th>\n",
              "      <th>GeographicField60A</th>\n",
              "      <th>GeographicField60B</th>\n",
              "      <th>GeographicField61A</th>\n",
              "      <th>GeographicField61B</th>\n",
              "      <th>GeographicField62A</th>\n",
              "      <th>GeographicField62B</th>\n",
              "      <th>GeographicField63</th>\n",
              "      <th>GeographicField64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-08-16</td>\n",
              "      <td>0</td>\n",
              "      <td>B</td>\n",
              "      <td>23</td>\n",
              "      <td>0.9403</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>965</td>\n",
              "      <td>1.0200</td>\n",
              "      <td>N</td>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>22</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>T</td>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>V</td>\n",
              "      <td>48649</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>-1</td>\n",
              "      <td>8</td>\n",
              "      <td>-1</td>\n",
              "      <td>18</td>\n",
              "      <td>-1</td>\n",
              "      <td>10</td>\n",
              "      <td>N</td>\n",
              "      <td>CA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2014-04-22</td>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0006</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>548</td>\n",
              "      <td>1.2433</td>\n",
              "      <td>N</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>T</td>\n",
              "      <td>E</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>P</td>\n",
              "      <td>26778</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>-1</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>-1</td>\n",
              "      <td>11</td>\n",
              "      <td>-1</td>\n",
              "      <td>17</td>\n",
              "      <td>-1</td>\n",
              "      <td>20</td>\n",
              "      <td>N</td>\n",
              "      <td>NJ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 299 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   QuoteNumber Original_Quote_Date  ...  GeographicField63 GeographicField64\n",
              "0            1          2013-08-16  ...                  N                CA\n",
              "1            2          2014-04-22  ...                  N                NJ\n",
              "\n",
              "[2 rows x 299 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "e48f9c29-0470-4f7f-813a-be785e067951",
        "outputId": "55a10fce-5ed3-4db8-ef76-cb81ee782b7b"
      },
      "source": [
        "df_test = pd.read_csv(path/\"test.csv\", low_memory=False)\n",
        "df_test.head(2)"
      ],
      "id": "e48f9c29-0470-4f7f-813a-be785e067951",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QuoteNumber</th>\n",
              "      <th>Original_Quote_Date</th>\n",
              "      <th>Field6</th>\n",
              "      <th>Field7</th>\n",
              "      <th>Field8</th>\n",
              "      <th>Field9</th>\n",
              "      <th>Field10</th>\n",
              "      <th>Field11</th>\n",
              "      <th>Field12</th>\n",
              "      <th>CoverageField1A</th>\n",
              "      <th>CoverageField1B</th>\n",
              "      <th>CoverageField2A</th>\n",
              "      <th>CoverageField2B</th>\n",
              "      <th>CoverageField3A</th>\n",
              "      <th>CoverageField3B</th>\n",
              "      <th>CoverageField4A</th>\n",
              "      <th>CoverageField4B</th>\n",
              "      <th>CoverageField5A</th>\n",
              "      <th>CoverageField5B</th>\n",
              "      <th>CoverageField6A</th>\n",
              "      <th>CoverageField6B</th>\n",
              "      <th>CoverageField8</th>\n",
              "      <th>CoverageField9</th>\n",
              "      <th>CoverageField11A</th>\n",
              "      <th>CoverageField11B</th>\n",
              "      <th>SalesField1A</th>\n",
              "      <th>SalesField1B</th>\n",
              "      <th>SalesField2A</th>\n",
              "      <th>SalesField2B</th>\n",
              "      <th>SalesField3</th>\n",
              "      <th>SalesField4</th>\n",
              "      <th>SalesField5</th>\n",
              "      <th>SalesField6</th>\n",
              "      <th>SalesField7</th>\n",
              "      <th>SalesField8</th>\n",
              "      <th>SalesField9</th>\n",
              "      <th>SalesField10</th>\n",
              "      <th>SalesField11</th>\n",
              "      <th>SalesField12</th>\n",
              "      <th>SalesField13</th>\n",
              "      <th>...</th>\n",
              "      <th>GeographicField44A</th>\n",
              "      <th>GeographicField44B</th>\n",
              "      <th>GeographicField45A</th>\n",
              "      <th>GeographicField45B</th>\n",
              "      <th>GeographicField46A</th>\n",
              "      <th>GeographicField46B</th>\n",
              "      <th>GeographicField47A</th>\n",
              "      <th>GeographicField47B</th>\n",
              "      <th>GeographicField48A</th>\n",
              "      <th>GeographicField48B</th>\n",
              "      <th>GeographicField49A</th>\n",
              "      <th>GeographicField49B</th>\n",
              "      <th>GeographicField50A</th>\n",
              "      <th>GeographicField50B</th>\n",
              "      <th>GeographicField51A</th>\n",
              "      <th>GeographicField51B</th>\n",
              "      <th>GeographicField52A</th>\n",
              "      <th>GeographicField52B</th>\n",
              "      <th>GeographicField53A</th>\n",
              "      <th>GeographicField53B</th>\n",
              "      <th>GeographicField54A</th>\n",
              "      <th>GeographicField54B</th>\n",
              "      <th>GeographicField55A</th>\n",
              "      <th>GeographicField55B</th>\n",
              "      <th>GeographicField56A</th>\n",
              "      <th>GeographicField56B</th>\n",
              "      <th>GeographicField57A</th>\n",
              "      <th>GeographicField57B</th>\n",
              "      <th>GeographicField58A</th>\n",
              "      <th>GeographicField58B</th>\n",
              "      <th>GeographicField59A</th>\n",
              "      <th>GeographicField59B</th>\n",
              "      <th>GeographicField60A</th>\n",
              "      <th>GeographicField60B</th>\n",
              "      <th>GeographicField61A</th>\n",
              "      <th>GeographicField61B</th>\n",
              "      <th>GeographicField62A</th>\n",
              "      <th>GeographicField62B</th>\n",
              "      <th>GeographicField63</th>\n",
              "      <th>GeographicField64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>2014-08-12</td>\n",
              "      <td>E</td>\n",
              "      <td>16</td>\n",
              "      <td>0.9364</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>1,487</td>\n",
              "      <td>1.3045</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>Y</td>\n",
              "      <td>K</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>P</td>\n",
              "      <td>67052</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>-1</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>20</td>\n",
              "      <td>-1</td>\n",
              "      <td>25</td>\n",
              "      <td>Y</td>\n",
              "      <td>IL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>2013-09-07</td>\n",
              "      <td>F</td>\n",
              "      <td>11</td>\n",
              "      <td>0.9919</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>564</td>\n",
              "      <td>1.1886</td>\n",
              "      <td>N</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>T</td>\n",
              "      <td>E</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>R</td>\n",
              "      <td>27288</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>-1</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>21</td>\n",
              "      <td>N</td>\n",
              "      <td>NJ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 298 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   QuoteNumber Original_Quote_Date  ... GeographicField63  GeographicField64\n",
              "0            3          2014-08-12  ...                 Y                 IL\n",
              "1            5          2013-09-07  ...                 N                 NJ\n",
              "\n",
              "[2 rows x 298 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a27a0d3-4c25-4374-9239-4adfc9d5a453"
      },
      "source": [
        "y_names = find_y_columns(df_train, df_test)[0]\n",
        "df_train, df_test, cont_names, cat_names = homesite_prep(df_train, df_test, y_names, category_threshold)"
      ],
      "id": "0a27a0d3-4c25-4374-9239-4adfc9d5a453",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be328797-a1af-4136-aecc-7006e443328e"
      },
      "source": [
        "procs = [Categorify, FillMissing, Normalize]\n",
        "splits = TrainTestSplitter(test_size=test_size, stratify=df_train[y_names])(df_train)"
      ],
      "id": "be328797-a1af-4136-aecc-7006e443328e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad7a983a-ca4f-4e5f-9adc-037c3abc96f0"
      },
      "source": [
        "to = TabularPandas(df=df_train, procs=procs, cat_names=cat_names, \n",
        "                   cont_names=cont_names, y_names=y_names,splits=splits,\n",
        "                  y_block=y_block)"
      ],
      "id": "ad7a983a-ca4f-4e5f-9adc-037c3abc96f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bajCVANOgnjY",
        "outputId": "4f0d4fae-cf9e-49c8-a956-437faec63c72"
      },
      "source": [
        "sampling_methods[0], sampling_methods[1]"
      ],
      "id": "bajCVANOgnjY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('uniform', 'gradient_based')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnZZeYwr8vJ0"
      },
      "source": [
        "## Exploring single parameter tuning performance"
      ],
      "id": "VnZZeYwr8vJ0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BBhrKp-9CM6"
      },
      "source": [
        "### n_estimators"
      ],
      "id": "0BBhrKp-9CM6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5368e3ad-8652-4d8a-b5d1-4eae6c97ce08",
        "outputId": "eee18348-5b50-457d-f073-5ebe9e4802aa"
      },
      "source": [
        "%time xgboost_tune_estimators(to.xs, to.ys.values.ravel(), n_estimators_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "5368e3ad-8652-4d8a-b5d1-4eae6c97ce08",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   30.4s\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  5.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.964941 using {'n_estimators': 450}\n",
            "0.953037 (0.000664) with: {'n_estimators': 50}\n",
            "0.957954 (0.000668) with: {'n_estimators': 100}\n",
            "0.960359 (0.000591) with: {'n_estimators': 150}\n",
            "0.961898 (0.000540) with: {'n_estimators': 200}\n",
            "0.962885 (0.000550) with: {'n_estimators': 250}\n",
            "0.963609 (0.000563) with: {'n_estimators': 300}\n",
            "0.964180 (0.000594) with: {'n_estimators': 350}\n",
            "0.964613 (0.000588) with: {'n_estimators': 400}\n",
            "0.964941 (0.000612) with: {'n_estimators': 450}\n",
            "CPU times: user 9.27 s, sys: 1.42 s, total: 10.7 s\n",
            "Wall time: 5min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zx5ivQyaa4-",
        "outputId": "b3e61254-f1e0-47fe-80a1-0691a2329d83"
      },
      "source": [
        "%time xgboost_tune_estimators(to.xs, to.ys.values.ravel(), n_estimators_range1, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "-zx5ivQyaa4-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 21.1min\n",
            "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed: 25.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966545 using {'n_estimators': 1000}\n",
            "0.965281 (0.000917) with: {'n_estimators': 500}\n",
            "0.965500 (0.000936) with: {'n_estimators': 550}\n",
            "0.965691 (0.000945) with: {'n_estimators': 600}\n",
            "0.965869 (0.000955) with: {'n_estimators': 650}\n",
            "0.966008 (0.000901) with: {'n_estimators': 700}\n",
            "0.966127 (0.000916) with: {'n_estimators': 750}\n",
            "0.966237 (0.000894) with: {'n_estimators': 800}\n",
            "0.966322 (0.000882) with: {'n_estimators': 850}\n",
            "0.966377 (0.000877) with: {'n_estimators': 900}\n",
            "0.966441 (0.000879) with: {'n_estimators': 950}\n",
            "0.966545 (0.000882) with: {'n_estimators': 1000}\n",
            "CPU times: user 26.1 s, sys: 1.63 s, total: 27.8 s\n",
            "Wall time: 25min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cagH9zqvapMb",
        "outputId": "0ded2511-40fb-41b5-cdf1-40e14d298c46"
      },
      "source": [
        "%time xgboost_tune_estimators(to.xs, to.ys.values.ravel(), n_estimators_range2, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "cagH9zqvapMb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 23.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966838 using {'n_estimators': 1400}\n",
            "0.966547 (0.000732) with: {'n_estimators': 1050}\n",
            "0.966608 (0.000750) with: {'n_estimators': 1100}\n",
            "0.966677 (0.000760) with: {'n_estimators': 1150}\n",
            "0.966705 (0.000746) with: {'n_estimators': 1200}\n",
            "0.966746 (0.000737) with: {'n_estimators': 1250}\n",
            "0.966796 (0.000750) with: {'n_estimators': 1300}\n",
            "0.966814 (0.000762) with: {'n_estimators': 1350}\n",
            "0.966838 (0.000758) with: {'n_estimators': 1400}\n",
            "0.966838 (0.000732) with: {'n_estimators': 1450}\n",
            "CPU times: user 25.6 s, sys: 2.16 s, total: 27.8 s\n",
            "Wall time: 23min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN8gCbFlarx_",
        "outputId": "1e4be74c-cd1f-4452-fb88-567f253c3fc2"
      },
      "source": [
        "%time xgboost_tune_estimators(to.xs, to.ys.values.ravel(), n_estimators_range3, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "aN8gCbFlarx_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.2min\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 32.6min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 36.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966902 using {'n_estimators': 1950}\n",
            "0.966850 (0.000720) with: {'n_estimators': 1550}\n",
            "0.966867 (0.000728) with: {'n_estimators': 1600}\n",
            "0.966880 (0.000725) with: {'n_estimators': 1650}\n",
            "0.966870 (0.000727) with: {'n_estimators': 1700}\n",
            "0.966897 (0.000728) with: {'n_estimators': 1750}\n",
            "0.966884 (0.000728) with: {'n_estimators': 1800}\n",
            "0.966889 (0.000721) with: {'n_estimators': 1850}\n",
            "0.966898 (0.000732) with: {'n_estimators': 1900}\n",
            "0.966902 (0.000735) with: {'n_estimators': 1950}\n",
            "0.966889 (0.000737) with: {'n_estimators': 2000}\n",
            "CPU times: user 33.2 s, sys: 2.44 s, total: 35.6 s\n",
            "Wall time: 36min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7k1cn6jFve8"
      },
      "source": [
        "From the batches we got from `0.964941 (0.000612) with: {'n_estimators': 450}` to `0.966902 (0.000735) with: {'n_estimators': 1950}` just tuning `n_estimators`"
      ],
      "id": "w7k1cn6jFve8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg47wz6u9HgI"
      },
      "source": [
        "### max_depth"
      ],
      "id": "tg47wz6u9HgI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDs8PaVLQMQ1",
        "outputId": "e866a8ec-fa68-43af-b1db-aaf99eec7dc0"
      },
      "source": [
        "%time xgboost_tune_max_depth(to.xs,to.ys.values.ravel(), max_depth_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "hDs8PaVLQMQ1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(1, 12, 2)\n",
            "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   31.8s\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  3.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.965565 using {'max_depth': 11}\n",
            "0.940100 (0.001024) with: {'max_depth': 1}\n",
            "0.957954 (0.000668) with: {'max_depth': 3}\n",
            "0.962320 (0.000596) with: {'max_depth': 5}\n",
            "0.964306 (0.000669) with: {'max_depth': 7}\n",
            "0.965231 (0.000838) with: {'max_depth': 9}\n",
            "0.965565 (0.000880) with: {'max_depth': 11}\n",
            "CPU times: user 6.8 s, sys: 1.42 s, total: 8.22 s\n",
            "Wall time: 3min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld_0LAfm9Cfp",
        "outputId": "3ac863f3-7173-4947-82ff-5b8ecd0d2d52"
      },
      "source": [
        "%time xgboost_tune_max_depth(to.xs,to.ys.values.ravel(), max_depth_range1, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "ld_0LAfm9Cfp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(13, 22, 2)\n",
            "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 26.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.965149 using {'max_depth': 13}\n",
            "0.965149 (0.000994) with: {'max_depth': 13}\n",
            "0.964474 (0.000903) with: {'max_depth': 15}\n",
            "0.964005 (0.000966) with: {'max_depth': 17}\n",
            "0.963855 (0.000978) with: {'max_depth': 19}\n",
            "0.963873 (0.000889) with: {'max_depth': 21}\n",
            "CPU times: user 14.4 s, sys: 1.82 s, total: 16.3 s\n",
            "Wall time: 26min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SalX1HSPGds7"
      },
      "source": [
        "With our two range checks, it seems like our best results come with `0.965565 (0.000880) with: {'max_depth': 11}` and seems to get worse after that, since `0.965149 (0.000994) with: {'max_depth': 13}` in the 2nd range checked is less than the best in the initial range chechked, and progressively gets worse. So we should do our final fine tuning of permutations of variables only with the first range for `max_depth` and skip tuning with the final range of max_depth"
      ],
      "id": "SalX1HSPGds7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAXMV46e9R2f"
      },
      "source": [
        "# %time xgboost_tune_max_depth(to.xs,to.ys.values.ravel(), max_depth_range2, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "CAXMV46e9R2f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ro_XabH9LJV"
      },
      "source": [
        "### learning_rate"
      ],
      "id": "7Ro_XabH9LJV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAvFd9YIwshD",
        "outputId": "759d8237-2a19-43b2-abb0-3d20d0c8ec57"
      },
      "source": [
        "%time xgboost_tune_lr(to.xs,to.ys.values.ravel(), learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "cAvFd9YIwshD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   41.0s\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.963524 using {'learning_rate': 0.3}\n",
            "0.870361 (0.002025) with: {'learning_rate': 0.0001}\n",
            "0.872141 (0.003595) with: {'learning_rate': 0.001}\n",
            "0.906749 (0.001726) with: {'learning_rate': 0.01}\n",
            "0.957872 (0.001386) with: {'learning_rate': 0.1}\n",
            "0.962143 (0.001049) with: {'learning_rate': 0.2}\n",
            "0.963524 (0.001038) with: {'learning_rate': 0.3}\n",
            "CPU times: user 4.03 s, sys: 1.58 s, total: 5.61 s\n",
            "Wall time: 1min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a7NogZFHwVL"
      },
      "source": [
        "The best learning rate, if just tuning that alone is `Best: 0.963524 using {'learning_rate': 0.3}`"
      ],
      "id": "7a7NogZFHwVL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T43e8kZtIfus",
        "outputId": "13bbb48e-f668-4fba-faa4-ab46a9a0c689"
      },
      "source": [
        "n_estimators_range[0:1], n_estimators_range[1:4], n_estimators_range[4:8]"
      ],
      "id": "T43e8kZtIfus",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(range(50, 100, 50), range(100, 250, 50), range(250, 450, 50))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4vn1jORIGpq",
        "outputId": "faed63dd-ea1d-414b-dfe6-3723b8fed9c5"
      },
      "source": [
        "n_estimators_agg_range = (n_estimators_range[0], n_estimators_range3[-1], 50)\n",
        "n_estimators_agg_range"
      ],
      "id": "i4vn1jORIGpq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 2000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tAKchlX9QUg"
      },
      "source": [
        "## Hypothesis: Multi-parameter vs Single parameter tuning\n",
        "> Test if tuning can lead to lower values and as good as or better metrics than single-parameter tuning alone"
      ],
      "id": "7tAKchlX9QUg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9y8TAxCIE0y"
      },
      "source": [
        "Hypothesis: We don't need as large a number of `n_estimators` to get at least as good as a validation metric as when we had a large value for `n_estimtors`\n",
        "Need to split up the ranges more to not timeout the run in Kaggle. Will stop 1 range after we get a validation metric equal to the `n_estimators=1950` value"
      ],
      "id": "R9y8TAxCIE0y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "171e1d9f-70a3-45e5-9a9b-05bb6ae1e5d7",
        "outputId": "47ee9297-ea13-4940-e06a-674fdbb0ff38"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.train.xs, to.train.ys.values.ravel(), n_estimators_range[0:1], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "171e1d9f-70a3-45e5-9a9b-05bb6ae1e5d7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(50, 100, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   22.5s\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 10.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.964010 using {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 50}\n",
            "0.751979 (0.003046) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 50}\n",
            "0.869145 (0.002477) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 50}\n",
            "0.922202 (0.006186) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 50}\n",
            "0.942591 (0.001473) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 50}\n",
            "0.950671 (0.001595) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 50}\n",
            "0.953800 (0.001254) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 50}\n",
            "0.751979 (0.003046) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 50}\n",
            "0.869156 (0.002472) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 50}\n",
            "0.923856 (0.005189) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 50}\n",
            "0.943740 (0.001201) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 50}\n",
            "0.951880 (0.001238) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 50}\n",
            "0.954835 (0.001105) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 50}\n",
            "0.751979 (0.003046) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
            "0.901847 (0.002123) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
            "0.937845 (0.001550) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
            "0.948545 (0.001346) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
            "0.954102 (0.001232) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
            "0.957146 (0.001086) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 50}\n",
            "0.910937 (0.002325) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
            "0.952633 (0.001445) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
            "0.957359 (0.001118) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
            "0.960241 (0.000898) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
            "0.962544 (0.000995) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
            "0.963453 (0.000948) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 50}\n",
            "0.938624 (0.001576) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 50}\n",
            "0.957635 (0.001107) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}\n",
            "0.961949 (0.000842) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}\n",
            "0.963619 (0.000812) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 50}\n",
            "0.964010 (0.000800) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 50}\n",
            "0.963526 (0.001098) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 50}\n",
            "0.944601 (0.001402) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 50}\n",
            "0.960327 (0.001075) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50}\n",
            "0.963439 (0.001099) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 50}\n",
            "0.963698 (0.001077) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 50}\n",
            "0.962492 (0.000850) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 50}\n",
            "0.961501 (0.001166) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 50}\n",
            "CPU times: user 10 s, sys: 8.4 s, total: 18.4 s\n",
            "Wall time: 10min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPR6CmMioGjk"
      },
      "source": [
        "`Best: 0.964010 using {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 50}` to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is already pretty close, but still isn't close enough to `0.966902 (0.000735) with: {'n_estimators': 1950}`"
      ],
      "id": "YPR6CmMioGjk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ofsvyzI_n0",
        "outputId": "c34840d7-3038-4292-a3ea-d9aa3fb6cb87"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.xs, to.ys.values.ravel(), n_estimators_range[1:2], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "W5ofsvyzI_n0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(100, 150, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   37.0s\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 21.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.965491 using {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}\n",
            "0.752885 (0.002114) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 100}\n",
            "0.870359 (0.001553) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.926093 (0.002292) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.942819 (0.001769) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 100}\n",
            "0.951621 (0.001413) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 100}\n",
            "0.954988 (0.001182) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 100}\n",
            "0.752885 (0.002114) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 100}\n",
            "0.873178 (0.003716) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.926634 (0.002313) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.945112 (0.001885) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 100}\n",
            "0.952877 (0.001527) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 100}\n",
            "0.956281 (0.001381) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 100}\n",
            "0.832564 (0.001216) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 100}\n",
            "0.907136 (0.002798) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.942553 (0.001768) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.951659 (0.001568) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100}\n",
            "0.956508 (0.001315) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 100}\n",
            "0.959096 (0.001204) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 100}\n",
            "0.940177 (0.001355) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100}\n",
            "0.957930 (0.001262) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.962430 (0.001106) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.964368 (0.001159) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
            "0.965283 (0.001170) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}\n",
            "0.965390 (0.001145) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 100}\n",
            "0.947208 (0.001327) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 100}\n",
            "0.962071 (0.001203) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.965159 (0.001172) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.965491 (0.001213) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}\n",
            "0.964716 (0.001151) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 100}\n",
            "0.963535 (0.001113) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 100}\n",
            "0.951080 (0.001339) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 100}\n",
            "0.963735 (0.001179) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.965322 (0.001224) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.964548 (0.001434) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 100}\n",
            "0.962934 (0.001425) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 100}\n",
            "0.961770 (0.001188) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 100}\n",
            "CPU times: user 14.9 s, sys: 3.2 s, total: 18.1 s\n",
            "Wall time: 21min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLP-VlJPsV5z"
      },
      "source": [
        "Best: `0.965491 using {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}`\n",
        "\n",
        "to our running best of : `Best: 0.964010 using {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 50}` is a good step up\n",
        "\n",
        "to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is already better\n",
        "\n",
        "to our individual parameter tuning best of `0.966902 (0.000735) with: {'n_estimators': 1950}` is not as good yet"
      ],
      "id": "hLP-VlJPsV5z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooZYynBmtQ3s",
        "outputId": "0a2e84d1-453d-48c4-e394-b1d4ca0fa275"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.xs, to.ys.values.ravel(), n_estimators_range[2:3], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "ooZYynBmtQ3s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(150, 200, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   47.6s\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 15.7min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 30.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.965929 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.752885 (0.002114) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 150}\n",
            "0.870359 (0.001553) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.926181 (0.002251) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.943161 (0.002037) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 150}\n",
            "0.951675 (0.001447) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 150}\n",
            "0.955047 (0.001206) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 150}\n",
            "0.752885 (0.002114) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 150}\n",
            "0.876144 (0.001286) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.929654 (0.002302) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.946549 (0.001667) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 150}\n",
            "0.953203 (0.001327) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 150}\n",
            "0.956743 (0.001438) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 150}\n",
            "0.832564 (0.001216) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 150}\n",
            "0.921982 (0.002077) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.944877 (0.002080) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.953576 (0.001472) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 150}\n",
            "0.957661 (0.001325) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 150}\n",
            "0.959992 (0.001179) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 150}\n",
            "0.944823 (0.001435) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 150}\n",
            "0.960446 (0.001184) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.964292 (0.001155) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.965639 (0.001191) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}\n",
            "0.965751 (0.001192) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 150}\n",
            "0.965469 (0.001118) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 150}\n",
            "0.950747 (0.001370) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 150}\n",
            "0.963729 (0.001213) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.965929 (0.001217) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.965486 (0.001286) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 150}\n",
            "0.964271 (0.001047) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 150}\n",
            "0.963260 (0.001186) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 150}\n",
            "0.953139 (0.001382) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 150}\n",
            "0.964877 (0.001168) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.965604 (0.001328) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.963946 (0.001444) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 150}\n",
            "0.962267 (0.001424) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 150}\n",
            "0.962203 (0.001134) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 150}\n",
            "CPU times: user 15.5 s, sys: 2.32 s, total: 17.8 s\n",
            "Wall time: 31min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WIaZNqdtRpP"
      },
      "source": [
        "Best: `0.965929 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}`\n",
        "\n",
        "to our running best of : `0.965491 using {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}` is slightly better\n",
        "\n",
        "to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is better\n",
        "\n",
        "to our individual parameter tuning best of `0.966902 (0.000735) with: {'n_estimators': 1950}` is not as good yet\n"
      ],
      "id": "0WIaZNqdtRpP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgO5pl1L2lBU",
        "outputId": "c074ea04-5f1a-4668-c967-21ee4ed30866"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.xs, to.ys.values.ravel(), n_estimators_range[3:4], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "ZgO5pl1L2lBU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(200, 250, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 20.9min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 41.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966138 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}\n",
            "0.752885 (0.002114) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 200}\n",
            "0.870359 (0.001553) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 200}\n",
            "0.926250 (0.002253) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 200}\n",
            "0.943344 (0.002040) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 200}\n",
            "0.951746 (0.001453) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 200}\n",
            "0.955191 (0.001309) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 200}\n",
            "0.752885 (0.002114) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 200}\n",
            "0.896939 (0.001870) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 200}\n",
            "0.933709 (0.003101) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 200}\n",
            "0.947491 (0.001635) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 200}\n",
            "0.953470 (0.001314) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 200}\n",
            "0.957012 (0.001366) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 200}\n",
            "0.862201 (0.001466) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 200}\n",
            "0.933365 (0.001476) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
            "0.948352 (0.001533) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
            "0.955065 (0.001480) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200}\n",
            "0.958781 (0.001261) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 200}\n",
            "0.960895 (0.001197) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 200}\n",
            "0.946916 (0.001392) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 200}\n",
            "0.961904 (0.001176) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
            "0.965339 (0.001210) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
            "0.966082 (0.001181) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
            "0.965795 (0.001199) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200}\n",
            "0.965349 (0.001140) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 200}\n",
            "0.952529 (0.001363) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 200}\n",
            "0.964721 (0.001225) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
            "0.966138 (0.001321) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}\n",
            "0.965302 (0.001219) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}\n",
            "0.963786 (0.001006) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 200}\n",
            "0.963365 (0.001264) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 200}\n",
            "0.954374 (0.001307) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 200}\n",
            "0.965573 (0.001305) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 200}\n",
            "0.965499 (0.001258) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 200}\n",
            "0.963438 (0.001267) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 200}\n",
            "0.962110 (0.001268) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 200}\n",
            "0.962387 (0.001110) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 200}\n",
            "CPU times: user 20.9 s, sys: 2.99 s, total: 23.8 s\n",
            "Wall time: 41min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxQzvCQz2laW"
      },
      "source": [
        "Best: `0.966138 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}`\n",
        "\n",
        "to our running best of : `0.965929 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}` is better\n",
        "\n",
        "to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is better\n",
        "\n",
        "to our individual parameter tuning best of `0.966902 (0.000735) with: {'n_estimators': 1950}` is just slightly worse off"
      ],
      "id": "zxQzvCQz2laW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfcC8pqLIlnP",
        "outputId": "23424e4f-2d1e-458f-d945-f140c0dc565a"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.xs, to.ys.values.ravel(), n_estimators_range[4:5], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "nfcC8pqLIlnP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(250, 300, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.0min\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 22.2min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 45.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966389 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 250}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 250}\n",
            "0.870360 (0.001705) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 250}\n",
            "0.926215 (0.001915) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 250}\n",
            "0.943307 (0.001374) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 250}\n",
            "0.951765 (0.001050) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 250}\n",
            "0.954981 (0.001106) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 250}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 250}\n",
            "0.901628 (0.002865) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 250}\n",
            "0.935802 (0.001789) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 250}\n",
            "0.947850 (0.001155) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 250}\n",
            "0.953761 (0.001109) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 250}\n",
            "0.957034 (0.000965) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 250}\n",
            "0.896926 (0.001422) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
            "0.943373 (0.001304) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
            "0.951410 (0.001134) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
            "0.956411 (0.001098) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
            "0.959704 (0.001012) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
            "0.961554 (0.001031) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 250}\n",
            "0.948739 (0.001135) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
            "0.962983 (0.001039) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
            "0.965813 (0.000917) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
            "0.966327 (0.000819) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
            "0.965787 (0.000926) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
            "0.964972 (0.000899) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 250}\n",
            "0.953481 (0.001111) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 250}\n",
            "0.965296 (0.000997) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 250}\n",
            "0.966389 (0.001085) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 250}\n",
            "0.965036 (0.000773) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 250}\n",
            "0.963644 (0.000851) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 250}\n",
            "0.963652 (0.000819) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 250}\n",
            "0.955416 (0.001211) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 250}\n",
            "0.965968 (0.001096) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 250}\n",
            "0.965435 (0.000856) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 250}\n",
            "0.962857 (0.001111) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 250}\n",
            "0.962074 (0.000712) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 250}\n",
            "0.962557 (0.000907) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 250}\n",
            "CPU times: user 19 s, sys: 2.96 s, total: 21.9 s\n",
            "Wall time: 45min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOUhBY78ImM5"
      },
      "source": [
        "Best: `0.966389 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 250}`\n",
        "\n",
        "to our running best of : `0.966138 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}` is slightly better\n",
        "\n",
        "to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is much better\n",
        "\n",
        "to our individual parameter tuning best of `0.966902 (0.000735) with: {'n_estimators': 1950}` is not yet better"
      ],
      "id": "sOUhBY78ImM5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EUSdqLV6EmG",
        "outputId": "43f05f5b-0400-4309-810e-aa41a435ef33"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.xs, to.ys.values.ravel(), n_estimators_range[5:6], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "3EUSdqLV6EmG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(300, 350, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 10.1min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 26.5min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 54.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966422 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 300}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 300}\n",
            "0.870359 (0.001705) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 300}\n",
            "0.926303 (0.001948) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 300}\n",
            "0.943667 (0.001428) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 300}\n",
            "0.951787 (0.001082) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 300}\n",
            "0.955087 (0.001107) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 300}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 300}\n",
            "0.903583 (0.001910) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
            "0.936403 (0.001723) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 300}\n",
            "0.948150 (0.001116) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 300}\n",
            "0.953947 (0.001114) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 300}\n",
            "0.957204 (0.000949) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 300}\n",
            "0.898274 (0.001634) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 300}\n",
            "0.947948 (0.001315) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
            "0.953170 (0.001111) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300}\n",
            "0.957402 (0.001064) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 300}\n",
            "0.960462 (0.001027) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 300}\n",
            "0.962134 (0.001052) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 300}\n",
            "0.950505 (0.001150) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 300}\n",
            "0.963692 (0.001049) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
            "0.966168 (0.000944) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
            "0.966366 (0.000865) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}\n",
            "0.965605 (0.000961) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300}\n",
            "0.964851 (0.000900) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 300}\n",
            "0.954250 (0.001165) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 300}\n",
            "0.965670 (0.000978) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 300}\n",
            "0.966422 (0.001029) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 300}\n",
            "0.964775 (0.000825) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300}\n",
            "0.963536 (0.000807) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 300}\n",
            "0.963716 (0.000844) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 300}\n",
            "0.956206 (0.001207) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 300}\n",
            "0.966172 (0.001072) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 300}\n",
            "0.965214 (0.000907) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 300}\n",
            "0.962569 (0.001178) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 300}\n",
            "0.962200 (0.000804) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 300}\n",
            "0.962703 (0.000914) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 300}\n",
            "CPU times: user 24.1 s, sys: 3.24 s, total: 27.3 s\n",
            "Wall time: 54min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIziT5PJ6FDz"
      },
      "source": [
        "Best: `0.966422 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 300}`\n",
        "\n",
        "to our running best of : `0.966389 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 250}` is slightly better\n",
        "\n",
        "to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is much better\n",
        "\n",
        "to our individual parameter tuning best of `0.966902 (0.000735) with: {'n_estimators': 1950}` is not quite better"
      ],
      "id": "JIziT5PJ6FDz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o993KAYFJOoE",
        "outputId": "14fe37d6-5966-4b62-bde0-d89085e1cd40"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.xs, to.ys.values.ravel(), n_estimators_range[6:7], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "o993KAYFJOoE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(350, 400, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.3min\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 30.7min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 63.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966364 using {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 350}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 350}\n",
            "0.870359 (0.001705) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 350}\n",
            "0.926368 (0.001834) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 350}\n",
            "0.943933 (0.001292) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 350}\n",
            "0.951854 (0.001094) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 350}\n",
            "0.955131 (0.001136) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 350}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 350}\n",
            "0.904082 (0.001852) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 350}\n",
            "0.937111 (0.001732) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 350}\n",
            "0.948413 (0.001086) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 350}\n",
            "0.954211 (0.001119) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 350}\n",
            "0.957343 (0.000912) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 350}\n",
            "0.904170 (0.001252) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 350}\n",
            "0.949571 (0.001256) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 350}\n",
            "0.954626 (0.001114) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 350}\n",
            "0.958239 (0.001046) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 350}\n",
            "0.961222 (0.001022) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 350}\n",
            "0.962727 (0.001037) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 350}\n",
            "0.951543 (0.001098) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 350}\n",
            "0.964213 (0.001006) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 350}\n",
            "0.966355 (0.000945) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 350}\n",
            "0.966364 (0.000883) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 350}\n",
            "0.965457 (0.000911) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 350}\n",
            "0.964757 (0.000847) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 350}\n",
            "0.954959 (0.001214) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 350}\n",
            "0.965975 (0.000986) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 350}\n",
            "0.966346 (0.000999) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 350}\n",
            "0.964533 (0.000798) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 350}\n",
            "0.963490 (0.000848) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 350}\n",
            "0.963839 (0.000856) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 350}\n",
            "0.956761 (0.001212) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 350}\n",
            "0.966328 (0.001051) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 350}\n",
            "0.964919 (0.000865) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 350}\n",
            "0.962367 (0.001163) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 350}\n",
            "0.962323 (0.000792) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 350}\n",
            "0.962775 (0.000912) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 350}\n",
            "CPU times: user 28.9 s, sys: 4.1 s, total: 33 s\n",
            "Wall time: 1h 3min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06df5_s1JPhF"
      },
      "source": [
        "Best: `0.966364 using {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 350}`\n",
        "\n",
        "to our running best of : `0.966422 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 300}` is getting worse\n",
        "\n",
        "to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is much better\n",
        "\n",
        "to our individual parameter tuning best of `0.966902 (0.000735) with: {'n_estimators': 1950}` is not quite better"
      ],
      "id": "06df5_s1JPhF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfYhljHFiU54",
        "outputId": "d9dbe7d0-e6bc-4ea9-8343-65fe85f9c527"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.xs, to.ys.values.ravel(), n_estimators_range[7:8], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "zfYhljHFiU54",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(400, 450, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.5min\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 13.4min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 35.0min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 71.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966493 using {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 400}\n",
            "0.870359 (0.001705) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 400}\n",
            "0.926426 (0.001848) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 400}\n",
            "0.944073 (0.001318) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 400}\n",
            "0.951963 (0.001093) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 400}\n",
            "0.955188 (0.001187) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 400}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 400}\n",
            "0.904183 (0.001830) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 400}\n",
            "0.937920 (0.001857) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 400}\n",
            "0.948551 (0.001133) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 400}\n",
            "0.954613 (0.001061) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 400}\n",
            "0.957465 (0.000926) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 400}\n",
            "0.904391 (0.001228) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 400}\n",
            "0.950882 (0.001214) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 400}\n",
            "0.955793 (0.001092) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 400}\n",
            "0.959033 (0.001034) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 400}\n",
            "0.961818 (0.001002) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 400}\n",
            "0.963299 (0.001046) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 400}\n",
            "0.952305 (0.001118) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 400}\n",
            "0.964645 (0.001052) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 400}\n",
            "0.966493 (0.000933) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}\n",
            "0.966339 (0.000897) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 400}\n",
            "0.965312 (0.000938) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 400}\n",
            "0.964762 (0.000891) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 400}\n",
            "0.955576 (0.001221) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 400}\n",
            "0.966138 (0.000939) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 400}\n",
            "0.966203 (0.001033) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 400}\n",
            "0.964334 (0.000765) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 400}\n",
            "0.963454 (0.000863) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 400}\n",
            "0.963840 (0.000869) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 400}\n",
            "0.957199 (0.001185) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 400}\n",
            "0.966369 (0.000997) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 400}\n",
            "0.964662 (0.000825) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 400}\n",
            "0.962201 (0.001143) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 400}\n",
            "0.962400 (0.000791) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 400}\n",
            "0.962836 (0.000900) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 400}\n",
            "CPU times: user 28.3 s, sys: 4.08 s, total: 32.3 s\n",
            "Wall time: 1h 11min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dva9zWJriVhb"
      },
      "source": [
        "Best: `0.966493 using {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}`\n",
        "\n",
        "to our running best of : `0.966422 using {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 300}` is a very slight improvement\n",
        "\n",
        "to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is better\n",
        "\n",
        "to our individual parameter tuning best of `0.966902 (0.000735) with: {'n_estimators': 1950}` is not as good"
      ],
      "id": "dva9zWJriVhb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuK1SHMF50-n"
      },
      "source": [
        "As we can see the most optimal parameters using XGBoost would be to do `n_estimators=300`, `max_depth=5`, `learning_rate=0.2`. Using default values of XGBoost from it's [source code](https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py#L362), Let's run both and compare results side by side"
      ],
      "id": "IuK1SHMF50-n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBfh2QGE0NBQ",
        "outputId": "9abdb19d-8ac2-4b5c-c7dd-2959eb7c7e62"
      },
      "source": [
        "%time xgboost_tune_n_estimators_and_max_depth_and_lr(to.xs, to.ys.values.ravel(), n_estimators_range[8:9], max_depth_range, learning_rate_range, n_splits, sampling_methods[1], random_seed, scoring)"
      ],
      "id": "uBfh2QGE0NBQ",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(450, 500, 50)\n",
            "range(1, 12, 2)\n",
            "[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 15.1min\n",
            "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 39.3min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 80.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.966590 using {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 450}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.0001, 'max_depth': 1, 'n_estimators': 450}\n",
            "0.870359 (0.001705) with: {'learning_rate': 0.0001, 'max_depth': 3, 'n_estimators': 450}\n",
            "0.926472 (0.001865) with: {'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 450}\n",
            "0.944154 (0.001364) with: {'learning_rate': 0.0001, 'max_depth': 7, 'n_estimators': 450}\n",
            "0.952004 (0.001115) with: {'learning_rate': 0.0001, 'max_depth': 9, 'n_estimators': 450}\n",
            "0.955253 (0.001215) with: {'learning_rate': 0.0001, 'max_depth': 11, 'n_estimators': 450}\n",
            "0.752885 (0.002099) with: {'learning_rate': 0.001, 'max_depth': 1, 'n_estimators': 450}\n",
            "0.904500 (0.001786) with: {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 450}\n",
            "0.938420 (0.001760) with: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 450}\n",
            "0.948791 (0.001086) with: {'learning_rate': 0.001, 'max_depth': 7, 'n_estimators': 450}\n",
            "0.954779 (0.001036) with: {'learning_rate': 0.001, 'max_depth': 9, 'n_estimators': 450}\n",
            "0.957578 (0.000942) with: {'learning_rate': 0.001, 'max_depth': 11, 'n_estimators': 450}\n",
            "0.904378 (0.001223) with: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 450}\n",
            "0.952087 (0.001192) with: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 450}\n",
            "0.956820 (0.001051) with: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 450}\n",
            "0.959711 (0.001031) with: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 450}\n",
            "0.962359 (0.000997) with: {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 450}\n",
            "0.963765 (0.001024) with: {'learning_rate': 0.01, 'max_depth': 11, 'n_estimators': 450}\n",
            "0.952845 (0.001125) with: {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 450}\n",
            "0.964971 (0.001040) with: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 450}\n",
            "0.966590 (0.000928) with: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 450}\n",
            "0.966272 (0.000936) with: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 450}\n",
            "0.965170 (0.000914) with: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 450}\n",
            "0.964778 (0.000910) with: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 450}\n",
            "0.956056 (0.001241) with: {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 450}\n",
            "0.966378 (0.000941) with: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 450}\n",
            "0.966093 (0.000996) with: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 450}\n",
            "0.964063 (0.000775) with: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 450}\n",
            "0.963464 (0.000851) with: {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 450}\n",
            "0.963881 (0.000905) with: {'learning_rate': 0.2, 'max_depth': 11, 'n_estimators': 450}\n",
            "0.957612 (0.001219) with: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 450}\n",
            "0.966507 (0.000966) with: {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 450}\n",
            "0.964433 (0.000775) with: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 450}\n",
            "0.962041 (0.001139) with: {'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 450}\n",
            "0.962471 (0.000799) with: {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 450}\n",
            "0.962890 (0.000927) with: {'learning_rate': 0.3, 'max_depth': 11, 'n_estimators': 450}\n",
            "CPU times: user 36.8 s, sys: 5.42 s, total: 42.2 s\n",
            "Wall time: 1h 20min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPQir3J50NkN"
      },
      "source": [
        "Best: `0.966590 using {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 450}`\n",
        "\n",
        "to our running best of : `0.966493 using {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}`is slightly better\n",
        "\n",
        "to our comparitor score for this range of `0.964941 (0.000612) with: {'n_estimators': 450}` is better\n",
        "\n",
        "to our individual parameter tuning best of `0.966902 (0.000735) with: {'n_estimators': 1950}` not quite as good"
      ],
      "id": "PPQir3J50NkN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBTUZpl393Yr"
      },
      "source": [
        "Ending here for now, as the run times were just getting too long, and we're really really close to comparative performance with the best single-parameter tuned result"
      ],
      "id": "BBTUZpl393Yr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibLnviPt8hO1"
      },
      "source": [
        "## Head to Head Comparisons: Default, vs Recommended vs Max parameter values"
      ],
      "id": "ibLnviPt8hO1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXKvBXU76EUO"
      },
      "source": [
        "n_estimators_original = 100\n",
        "max_depth_original = 6\n",
        "learning_rate_original = 0.2\n",
        "\n",
        "n_estimators_recommended = 450\n",
        "max_depth_recommended = 5\n",
        "learning_rate_recommended = 0.1\n",
        "\n",
        "n_estimators_max = 1950\n",
        "subsample = 1\n",
        "enable_categorical=True"
      ],
      "id": "zXKvBXU76EUO",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2xie4-X6bQz"
      },
      "source": [
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_valid, y_valid = to.valid.xs, to.valid.ys.values.ravel()"
      ],
      "id": "f2xie4-X6bQz",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RxgCDVi6nXF",
        "outputId": "68df548f-574e-4d82-998f-2053e5b5051b"
      },
      "source": [
        "model_original = xgb.XGBClassifier(n_estimators = n_estimators_original, max_depth=max_depth_original, learning_rate=learning_rate_original, subsample=subsample, \n",
        "                                  tree_method='gpu_hist', gpu_id=0, verbosity=2, enable_categorical=enable_categorical, sampling_methods=sampling_methods[1])\n",
        "%time xgb_model_original = model_original.fit(X_train, y_train)\n",
        "xgb_preds_original = xgb_model_original.predict_proba(X_valid)\n",
        "xgb_preds_original\n"
      ],
      "id": "1RxgCDVi6nXF",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.24 s, sys: 246 ms, total: 2.49 s\n",
            "Wall time: 2.47 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9646646e-01, 3.5335247e-03],\n",
              "       [9.9989974e-01, 1.0023018e-04],\n",
              "       [7.9425681e-01, 2.0574318e-01],\n",
              "       ...,\n",
              "       [9.8356736e-01, 1.6432654e-02],\n",
              "       [4.6183008e-01, 5.3816992e-01],\n",
              "       [9.6087682e-01, 3.9123163e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGoo4lQa7i-d",
        "outputId": "2a4ec452-678b-4b24-c6b9-d64eea7d9f19"
      },
      "source": [
        "model_recommended = xgb.XGBClassifier(n_estimators = n_estimators_recommended, max_depth=max_depth_recommended, learning_rate=learning_rate_recommended, subsample=subsample,\n",
        "                                    tree_method='gpu_hist', gpu_id=0, verbosity=3, enable_categorical=enable_categorical, sampling_methods=sampling_methods[1])\n",
        "%time xgb_model_recommended = model_recommended.fit(X_train, y_train)\n",
        "xgb_preds_recommended = xgb_model_recommended.predict_proba(X_valid)\n",
        "xgb_preds_recommended"
      ],
      "id": "dGoo4lQa7i-d",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.78 s, sys: 224 ms, total: 6.01 s\n",
            "Wall time: 5.96 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9579751e-01, 4.2025056e-03],\n",
              "       [9.9995327e-01, 4.6750749e-05],\n",
              "       [7.4739861e-01, 2.5260136e-01],\n",
              "       ...,\n",
              "       [9.8437619e-01, 1.5623793e-02],\n",
              "       [5.1231825e-01, 4.8768175e-01],\n",
              "       [9.5093983e-01, 4.9060162e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO014EEyKqAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679a103f-dc65-4ae0-fc0f-8bf2c41175b0"
      },
      "source": [
        "model_max_e = xgb.XGBClassifier(n_estimators = n_estimators_max, max_depth=max_depth_recommended, learning_rate=learning_rate_recommended, subsample=subsample, \n",
        "                                  tree_method='gpu_hist', gpu_id=0, verbosity=2, enable_categorical=enable_categorical, sampling_methods=sampling_methods[1])\n",
        "%time xgb_model_max_e = model_max_e.fit(X_train, y_train)\n",
        "xgb_preds_max_e = xgb_model_max_e.predict_proba(X_valid)\n",
        "xgb_preds_max_e"
      ],
      "id": "xO014EEyKqAj",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 21.6 s, sys: 315 ms, total: 22 s\n",
            "Wall time: 21.8 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9950659e-01, 4.9340865e-04],\n",
              "       [9.9998891e-01, 1.1102343e-05],\n",
              "       [8.0084145e-01, 1.9915855e-01],\n",
              "       ...,\n",
              "       [9.9154103e-01, 8.4589710e-03],\n",
              "       [5.5457193e-01, 4.4542807e-01],\n",
              "       [9.7199428e-01, 2.8005721e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWdLGC0t7PfP",
        "outputId": "70324baf-39d1-4331-fb29-7b1e72d586c7"
      },
      "source": [
        "accuracy(tensor(xgb_preds_original), tensor(y_valid)), accuracy(tensor(xgb_preds_recommended), tensor(y_valid)), accuracy(tensor(xgb_preds_max_e), tensor(y_valid))"
      ],
      "id": "tWdLGC0t7PfP",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorBase(0.9254), TensorBase(0.9271), TensorBase(0.9255))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8tV3D34-GCT",
        "outputId": "b6cfb640-09ed-48b7-a05f-a8b856ff65ad"
      },
      "source": [
        "roc_auc_score(y_score=tensor(xgb_preds_original[:,1:2]), y_true=tensor(y_valid)), roc_auc_score(y_score=tensor(xgb_preds_recommended[:,1:2]), y_true=tensor(y_valid)), roc_auc_score(y_score=tensor(xgb_preds_max_e[:,1:2]), y_true=tensor(y_valid))"
      ],
      "id": "d8tV3D34-GCT",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9651362820976437, 0.9657186586961237, 0.9643268132563287)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6A9ISXW-M_Q"
      },
      "source": [
        "So as we can see, we get a slightly better performance both in accuracy and the `roc_auc_score` (used in Kaggle competition) when we use a lower `n_estimators` and tune together with `max_depth` and `learning_rate` parameters based on the recommendation, than either when we use just the defaults or the maximum value of `n_estimators`"
      ],
      "id": "E6A9ISXW-M_Q"
    }
  ]
}