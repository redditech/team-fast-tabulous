{
  
    
        "post0": {
            "title": "Identify problem type",
            "content": "# Install packages recommended in fastbook Ch09 !pip install -Uqq fastbook kaggle waterfallcharts treeinterpreter dtreeviz . import fastbook fastbook.setup_book() . Mounted at /content/gdrive . from fastbook import * from fastai.vision.widgets import * from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype from fastai.tabular.all import * from sklearn.ensemble import RandomForestRegressor from sklearn.tree import DecisionTreeRegressor from dtreeviz.trees import * from IPython.display import Image, display_svg, SVG pd.options.display.max_rows = 20 pd.options.display.max_columns = 8 . # Upload your kaggle.json API key btn_upload = widgets.FileUpload(description=&quot;kaggle.json&quot;) btn_upload . # Save credentials cred_path = Path(&#39;~/.kaggle/kaggle.json&#39;).expanduser() if not cred_path.parent.exists(): cred_path.parent.mkdir() if len(btn_upload.data) &gt; 0: with open(cred_path, mode=&quot;wb&quot;) as cred_file: cred_file.write(btn_upload.data[-1]) cred_path.chmod(0o600) . from kaggle import api . # Note that &#39;!pip install kaggle&#39; does not update cli kaggle in Google colab # and is only v1.5.4 while kaggle.api is v1.5.12 !kaggle --version . Kaggle API 1.5.4 . # python kaggle.api is using a more recent version api.__version__ . &#39;1.5.12&#39; . # Get data from kaggle, extract and store in _data path_hqc = (Path.cwd()/&quot;_data&quot;) path_hqc.mkdir(exist_ok=True) Path.BASE_PATH = path_hqc api.competition_download_cli(&#39;homesite-quote-conversion&#39;, path=path_hqc) file_extract(path_hqc/&quot;homesite-quote-conversion.zip&quot;) file_extract(path_hqc/&quot;train.csv.zip&quot;) file_extract(path_hqc/&quot;test.csv.zip&quot;) . 0%| | 0.00/62.0M [00:00&lt;?, ?B/s] . Downloading homesite-quote-conversion.zip to /content/_data . 100%|██████████| 62.0M/62.0M [00:00&lt;00:00, 75.9MB/s] . . # Check what the data looks like df = pd.read_csv(path_hqc/&quot;train.csv&quot;, low_memory=False) df.head() . QuoteNumber Original_Quote_Date QuoteConversion_Flag Field6 ... GeographicField62A GeographicField62B GeographicField63 GeographicField64 . 0 1 | 2013-08-16 | 0 | B | ... | -1 | 10 | N | CA | . 1 2 | 2014-04-22 | 0 | F | ... | -1 | 20 | N | NJ | . 2 4 | 2014-08-25 | 0 | F | ... | -1 | 8 | N | NJ | . 3 6 | 2013-04-15 | 0 | J | ... | -1 | 21 | N | TX | . 4 8 | 2014-01-25 | 0 | E | ... | -1 | 12 | N | IL | . 5 rows × 299 columns . # Check how much data we have and check if QuoteNumber is unique df.shape, len(df[&#39;QuoteNumber&#39;].unique()) # Conclusion: QuoteNumber is unique . ((260753, 299), 260753) . # We don&#39;t want to use QuoteNumber as a feature but we could use it as the index df = df.set_index(&#39;QuoteNumber&#39;) . # Examine data types in train.csv df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: float64(6), int64(264), object(28) memory usage: 594.8+ MB . # Find the 28 fields which do not have numeric datatypes from collections import defaultdict dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) print(&quot;dtypes in train.csv:&quot;, dct_fields_by_dtype.keys()) print(&quot;fields for object dtype:&quot;, dct_fields_by_dtype[np.dtype(&#39;O&#39;)]) print(&quot;number of fields of object dtype:&quot;, len(dct_fields_by_dtype[np.dtype(&#39;O&#39;)])) . dtypes in train.csv: dict_keys([dtype(&#39;O&#39;), dtype(&#39;int64&#39;), dtype(&#39;float64&#39;)]) fields for object dtype: [&#39;Original_Quote_Date&#39;, &#39;Field6&#39;, &#39;Field10&#39;, &#39;Field12&#39;, &#39;CoverageField8&#39;, &#39;CoverageField9&#39;, &#39;SalesField7&#39;, &#39;PersonalField7&#39;, &#39;PersonalField16&#39;, &#39;PersonalField17&#39;, &#39;PersonalField18&#39;, &#39;PersonalField19&#39;, &#39;PropertyField3&#39;, &#39;PropertyField4&#39;, &#39;PropertyField5&#39;, &#39;PropertyField7&#39;, &#39;PropertyField14&#39;, &#39;PropertyField28&#39;, &#39;PropertyField30&#39;, &#39;PropertyField31&#39;, &#39;PropertyField32&#39;, &#39;PropertyField33&#39;, &#39;PropertyField34&#39;, &#39;PropertyField36&#39;, &#39;PropertyField37&#39;, &#39;PropertyField38&#39;, &#39;GeographicField63&#39;, &#39;GeographicField64&#39;] number of fields of object dtype: 28 . # Original_Quote_Date can be converted to datetime df[&#39;Original_Quote_Date&#39;] = pd.to_datetime(df[&#39;Original_Quote_Date&#39;]) # recalculate breakdown now that we have changed dtype of Original_Quote_Date dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: datetime64[ns](1), float64(6), int64(264), object(27) memory usage: 594.8+ MB . # Compare Original_Quote_Date in train.csv and test.csv df_test = pd.read_csv(path_hqc/&quot;test.csv&quot;, low_memory=False) df_test[&quot;Original_Quote_Date&quot;] = pd.to_datetime(df_test[&quot;Original_Quote_Date&quot;]) print(&quot;train.csv&quot;, df[&#39;Original_Quote_Date&#39;].min(), df[&#39;Original_Quote_Date&#39;].max(), df.shape) print(&quot;test.csv &quot;, df_test[&#39;Original_Quote_Date&#39;].min(), df_test[&#39;Original_Quote_Date&#39;].max(), df_test.shape) # Conclusion: overlapping date ranges (in fact identical date ranges) so # don&#39;t need to consider as time series problem . train.csv 2013-01-01 00:00:00 2015-05-18 00:00:00 (260753, 298) test.csv 2013-01-01 00:00:00 2015-05-18 00:00:00 (173836, 298) . # Check the non-numeric values in other object fields for col in dct_fields_by_dtype[np.dtype(&#39;O&#39;)]: print(f&quot;{col:20s} {df[col].unique()}&quot;) . Field6 [&#39;B&#39; &#39;F&#39; &#39;J&#39; &#39;E&#39; &#39;C&#39; &#39;K&#39; &#39;A&#39; &#39;D&#39;] Field10 [&#39;965&#39; &#39;548&#39; &#39;1,165&#39; &#39;1,487&#39; &#39;935&#39; &#39;564&#39; &#39;1,113&#39; &#39;1,480&#39;] Field12 [&#39;N&#39; &#39;Y&#39;] CoverageField8 [&#39;T&#39; &#39;Y&#39; &#39;X&#39; &#39;W&#39; &#39;V&#39; &#39;U&#39; &#39;Z&#39;] CoverageField9 [&#39;D&#39; &#39;E&#39; &#39;J&#39; &#39;F&#39; &#39;A&#39; &#39;G&#39; &#39;K&#39; &#39;C&#39; &#39;L&#39; &#39;B&#39; &#39;I&#39; &#39;H&#39;] SalesField7 [&#39;V&#39; &#39;P&#39; &#39;K&#39; &#39;R&#39; &#39;T&#39; &#39;Q&#39; &#39;M&#39;] PersonalField7 [&#39;N&#39; &#39;Y&#39; nan] PersonalField16 [&#39;ZA&#39; &#39;XB&#39; &#39;ZH&#39; &#39;XO&#39; &#39;YE&#39; &#39;XR&#39; &#39;ZG&#39; &#39;ZF&#39; &#39;XW&#39; &#39;XS&#39; &#39;ZT&#39; &#39;XD&#39; &#39;XH&#39; &#39;XM&#39; &#39;YH&#39; &#39;ZD&#39; &#39;XJ&#39; &#39;ZN&#39; &#39;YF&#39; &#39;XX&#39; &#39;XL&#39; &#39;XQ&#39; &#39;ZJ&#39; &#39;ZR&#39; &#39;ZW&#39; &#39;XE&#39; &#39;XC&#39; &#39;ZK&#39; &#39;XK&#39; &#39;ZC&#39; &#39;XZ&#39; &#39;XI&#39; &#39;ZE&#39; &#39;ZU&#39; &#39;YI&#39; &#39;XP&#39; &#39;ZO&#39; &#39;ZP&#39; &#39;ZB&#39; &#39;XF&#39; &#39;ZS&#39; &#39;XT&#39; &#39;XY&#39; &#39;ZQ&#39; &#39;ZI&#39; &#39;XV&#39; &#39;XU&#39; &#39;XN&#39; &#39;ZV&#39; &#39;ZL&#39;] PersonalField17 [&#39;ZE&#39; &#39;YJ&#39; &#39;XS&#39; &#39;XE&#39; &#39;XU&#39; &#39;ZQ&#39; &#39;YY&#39; &#39;XV&#39; &#39;ZF&#39; &#39;XK&#39; &#39;YS&#39; &#39;ZK&#39; &#39;YF&#39; &#39;YV&#39; &#39;XG&#39; &#39;ZL&#39; &#39;ZH&#39; &#39;ZW&#39; &#39;XH&#39; &#39;ZU&#39; &#39;YH&#39; &#39;XC&#39; &#39;ZV&#39; &#39;XR&#39; &#39;ZI&#39; &#39;XX&#39; &#39;YR&#39; &#39;XW&#39; &#39;ZC&#39; &#39;YZ&#39; &#39;YU&#39; &#39;YX&#39; &#39;ZA&#39; &#39;ZP&#39; &#39;XI&#39; &#39;YN&#39; &#39;YL&#39; &#39;YK&#39; &#39;ZN&#39; &#39;XT&#39; &#39;ZT&#39; &#39;XQ&#39; &#39;XB&#39; &#39;YI&#39; &#39;YM&#39; &#39;XL&#39; &#39;YQ&#39; &#39;ZG&#39; &#39;ZS&#39; &#39;YT&#39; &#39;ZO&#39; &#39;YE&#39; &#39;XN&#39; &#39;ZM&#39; &#39;XM&#39; &#39;YG&#39; &#39;YP&#39; &#39;XD&#39; &#39;ZD&#39; &#39;YW&#39; &#39;XJ&#39; &#39;ZB&#39; &#39;XP&#39; &#39;XO&#39; &#39;ZR&#39; &#39;XY&#39;] PersonalField18 [&#39;XR&#39; &#39;YE&#39; &#39;YP&#39; &#39;YI&#39; &#39;XQ&#39; &#39;ZW&#39; &#39;XT&#39; &#39;XF&#39; &#39;XS&#39; &#39;YG&#39; &#39;ZF&#39; &#39;XZ&#39; &#39;XI&#39; &#39;XK&#39; &#39;YF&#39; &#39;ZE&#39; &#39;YQ&#39; &#39;ZP&#39; &#39;YL&#39; &#39;ZD&#39; &#39;XW&#39; &#39;YN&#39; &#39;YK&#39; &#39;ZJ&#39; &#39;ZK&#39; &#39;ZC&#39; &#39;XU&#39; &#39;ZN&#39; &#39;XP&#39; &#39;XL&#39; &#39;XM&#39; &#39;ZL&#39; &#39;XC&#39; &#39;ZH&#39; &#39;XG&#39; &#39;XN&#39; &#39;XY&#39; &#39;ZQ&#39; &#39;XO&#39; &#39;ZT&#39; &#39;XJ&#39; &#39;ZA&#39; &#39;ZU&#39; &#39;XE&#39; &#39;ZV&#39; &#39;ZS&#39; &#39;YR&#39; &#39;YH&#39; &#39;YJ&#39; &#39;ZR&#39; &#39;ZO&#39; &#39;YO&#39; &#39;ZM&#39; &#39;XD&#39; &#39;YM&#39; &#39;XX&#39; &#39;ZB&#39; &#39;XH&#39; &#39;XV&#39; &#39;ZG&#39; &#39;ZI&#39;] PersonalField19 [&#39;XD&#39; &#39;XT&#39; &#39;XC&#39; &#39;XX&#39; &#39;ZQ&#39; &#39;ZT&#39; &#39;ZO&#39; &#39;YJ&#39; &#39;ZN&#39; &#39;YH&#39; &#39;ZI&#39; &#39;YN&#39; &#39;YF&#39; &#39;YK&#39; &#39;XY&#39; &#39;XI&#39; &#39;ZA&#39; &#39;ZW&#39; &#39;ZV&#39; &#39;XU&#39; &#39;ZL&#39; &#39;XK&#39; &#39;XW&#39; &#39;XF&#39; &#39;ZK&#39; &#39;YE&#39; &#39;XB&#39; &#39;XZ&#39; &#39;XP&#39; &#39;ZJ&#39; &#39;YM&#39; &#39;XO&#39; &#39;YG&#39; &#39;XN&#39; &#39;ZR&#39; &#39;ZE&#39; &#39;ZB&#39; &#39;ZG&#39; &#39;YL&#39; &#39;ZF&#39; &#39;XR&#39; &#39;XJ&#39; &#39;XM&#39; &#39;ZP&#39; &#39;XQ&#39; &#39;XV&#39; &#39;ZH&#39; &#39;XE&#39; &#39;ZU&#39; &#39;ZM&#39; &#39;XG&#39; &#39;ZD&#39; &#39;XH&#39; &#39;XL&#39; &#39;YI&#39; &#39;XS&#39; &#39;ZC&#39;] PropertyField3 [&#39;N&#39; &#39;Y&#39; nan] PropertyField4 [&#39;N&#39; &#39;Y&#39; nan] PropertyField5 [&#39;Y&#39; &#39;N&#39;] PropertyField7 [&#39;O&#39; &#39;N&#39; &#39;R&#39; &#39;D&#39; &#39;S&#39; &#39;J&#39; &#39;I&#39; &#39;Q&#39; &#39;A&#39; &#39;K&#39; &#39;G&#39; &#39;F&#39; &#39;H&#39; &#39;E&#39; &#39;L&#39; &#39;C&#39; &#39;P&#39; &#39;M&#39; &#39;B&#39;] PropertyField14 [&#39;C&#39; &#39;B&#39; &#39;A&#39; &#39;D&#39;] PropertyField28 [&#39;B&#39; &#39;D&#39; &#39;A&#39; &#39;C&#39;] PropertyField30 [&#39;N&#39; &#39;Y&#39;] PropertyField31 [&#39;N&#39; &#39;O&#39; &#39;K&#39; &#39;M&#39;] PropertyField32 [&#39;Y&#39; &#39;N&#39; nan] PropertyField33 [&#39;G&#39; &#39;H&#39; &#39;E&#39; &#39;F&#39;] PropertyField34 [&#39;Y&#39; &#39;N&#39; nan] PropertyField36 [&#39;N&#39; &#39;Y&#39; nan] PropertyField37 [&#39;N&#39; &#39;Y&#39;] PropertyField38 [&#39;N&#39; &#39;Y&#39; nan] GeographicField63 [&#39;N&#39; &#39;Y&#39; &#39; &#39;] GeographicField64 [&#39;CA&#39; &#39;NJ&#39; &#39;TX&#39; &#39;IL&#39;] . # Field10 looks like integers stored as strings so convert to ints df[&#39;Field10&#39;] = df[&#39;Field10&#39;].str.replace(&quot;,&quot;, &quot;&quot;).astype(int) df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: datetime64[ns](1), float64(6), int64(265), object(26) memory usage: 594.8+ MB . # recalculate breakdown now that we have changed dtype of Field10 dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) .",
            "url": "https://redditech.github.io/team-fast-tabulous/jupyter/2021/06/20/Identify-problem-type.html",
            "relUrl": "/jupyter/2021/06/20/Identify-problem-type.html",
            "date": " • Jun 20, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Basic Random Forest Model Kaggle Score 0.953",
            "content": "This is a Colab notebook. Basic Random Forest Model without any hyperparameter tuning and feature engineering. Kaggle Score 0.953. This can be a baseline model . import pandas as pd import numpy as np from sklearn.ensemble import RandomForestClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score from sklearn.metrics import mean_squared_error from sklearn.metrics import plot_roc_curve from sklearn.metrics import plot_confusion_matrix from sklearn.metrics import roc_auc_score import matplotlib.pyplot as plt from fastbook import * from fastai.tabular.all import * from dtreeviz.trees import * from IPython.display import Image, display_svg, SVG import random as rd pd.options.display.max_rows = 20 pd.options.display.max_columns = 8 . Download Data From Kaggle . !mkdir -p ~/.kaggle !cp /content/gdrive/MyDrive/Kaggle/kaggle.json ~/.kaggle/ !chmod 600 ~/.kaggle/kaggle.json . path = Path(&#39;/content/gdrive/MyDrive/Kaggle/&#39; + &#39;data/homesite-quote&#39;) path.mkdir(parents=True, exist_ok=True) path . Path(&#39;/content/gdrive/MyDrive/Kaggle/data/homesite-quote&#39;) . !kaggle competitions download -c homesite-quote-conversion -p /content/gdrive/MyDrive/Kaggle/data/homesite-quote . Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) Downloading train.csv.zip to /content/gdrive/MyDrive/Kaggle/data/homesite-quote 89% 33.0M/37.1M [00:00&lt;00:00, 63.7MB/s] 100% 37.1M/37.1M [00:00&lt;00:00, 83.8MB/s] Downloading sample_submission.csv.zip to /content/gdrive/MyDrive/Kaggle/data/homesite-quote 0% 0.00/258k [00:00&lt;?, ?B/s] 100% 258k/258k [00:00&lt;00:00, 36.1MB/s] Downloading test.csv.zip to /content/gdrive/MyDrive/Kaggle/data/homesite-quote 53% 13.0M/24.7M [00:00&lt;00:00, 68.0MB/s] 100% 24.7M/24.7M [00:00&lt;00:00, 82.5MB/s] . ! unzip -q -n &#39;{path}/train.csv.zip&#39; -d &#39;{path}&#39; ! unzip -q -n &#39;{path}/test.csv.zip&#39; -d &#39;{path}&#39; . Import Data . df = pd.read_csv(path/&#39;train.csv&#39;, low_memory=False) test_df = pd.read_csv(path/&#39;test.csv&#39;, low_memory=False) . Data Prep . def drop_cols(df): df.drop([&#39;Original_Quote_Date&#39;],axis=1,inplace=True) return df train_df=df train_df = drop_cols(train_df) test_df = drop_cols(test_df) . cols_to_delete = train_df.isna().sum()[train_df.isna().sum() &gt; 0].index def drop_cols_from_list(df,cols_to_delete): df.drop(cols_to_delete,axis=1,inplace=True) return df train_df = drop_cols_from_list(train_df,cols_to_delete) test_df = drop_cols_from_list(test_df,cols_to_delete) . cols_to_drop = [] for i in set(train_df.columns) - set(train_df._get_numeric_data().columns): if (train_df.loc[:,i].nunique() &gt;= 3): cols_to_drop.append(i) train_df = drop_cols_from_list(train_df,cols_to_drop) test_df = drop_cols_from_list(test_df,cols_to_drop) . cls_to_encode = set(train_df.columns) - set(train_df._get_numeric_data().columns) def ohe(df,cls_to_encode): df = pd.get_dummies(df,columns=cls_to_encode,drop_first=True) return df train_df = ohe(train_df,cls_to_encode) test_df = ohe(test_df,cls_to_encode) . test_df.drop(list(set(test_df.columns) - set(train_df.columns)),axis=1,inplace=True) . Model . X = train_df.drop(&#39;QuoteConversion_Flag&#39;,axis=1) y = train_df.QuoteConversion_Flag . X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state=42) . train_idx=pd.DataFrame(X_train.index) valid_idx=pd.DataFrame(X_test.index) . train_idx.to_csv(path/&#39;train_idx.csv&#39;,index=False) valid_idx.to_csv(path/&#39;valid_idx.csv&#39;,index=False) . rfc = RandomForestClassifier(n_jobs=-1) rfc.fit(X_train,y_train) . RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1, oob_score=False, random_state=None, verbose=0, warm_start=False) . print(&quot;train accuracy score = &quot;, accuracy_score(y_train,rfc.predict(X_train))) print(&quot;test accuracy score = &quot;, accuracy_score(y_test,rfc.predict(X_test))) . train accuracy score = 0.9999952061821076 test accuracy score = 0.9162623919004429 . roc_auc_score(y_train,rfc.predict(X_train)),roc_auc_score(y_test,rfc.predict(X_test)) . (0.9999872171801099, 0.8078645543138884) . plot_roc_curve(rfc, X_test, y_test) plt.show() . plot_confusion_matrix(rfc, X_test, y_test,values_format=&#39;d&#39;) plt.show() . output_submission = pd.DataFrame(zip(test_df.QuoteNumber,rfc.predict_proba(test_df)[:,1]), columns = [&#39;QuoteNumber&#39;,&#39;QuoteConversion_Flag&#39;]) output_submission.to_csv(path/&#39;output_submission.csv&#39;,index=False) .",
            "url": "https://redditech.github.io/team-fast-tabulous/jupyter/2021/06/20/Basic-Random-Forest-Score-0.953.html",
            "relUrl": "/jupyter/2021/06/20/Basic-Random-Forest-Score-0.953.html",
            "date": " • Jun 20, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Getting Kaggle Data for Homesite",
            "content": "Introduction . This notebook is a demonstration of what I did to get the Homesite competition data from Kaggle. . Tools . If you haven&#39;t installed the Kaggle tools, you would need to do so like this . !pip install kaggle --upgrade . Requirement already satisfied: kaggle in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (1.5.12) Requirement already satisfied: tqdm in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (4.59.0) Requirement already satisfied: requests in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2.25.1) Requirement already satisfied: python-slugify in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (5.0.2) Requirement already satisfied: urllib3 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (1.26.4) Requirement already satisfied: python-dateutil in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2.8.1) Requirement already satisfied: certifi in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2021.5.30) Requirement already satisfied: six&gt;=1.10 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (1.16.0) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests-&gt;kaggle) (4.0.0) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests-&gt;kaggle) (2.10) . Then you need to download your Kaggle key following the instructions here . You may need to create the ~/.kaggle directory manually before copying the downloaded file kaggle.json file to that folder. . Follow the instructions as coded to download the kaggle data. For me, I use a _data folder that is excluded from checkins in the .gitignore to make sure I do not inadvertently upload it when I check in any changes to the repository, since I&#39;m writing this blog post as I am coding. I&#39;m not using any of the tabular stuff from fastai library yet, but I want to use some of the nice utility functions it gives me to make sure I do the command line stuff correctly and capture it in the notebook. So I need to install it. . !mamba install -c fastchan fastai -y . __ __ __ __ / / / / / / / / ███████████████/ /██/ /██/ /██/ /████████████████████████ / / / / / ____ / / _/ _/ _/ o __, / _/ _____/ ` |/ ███╗ ███╗ █████╗ ███╗ ███╗██████╗ █████╗ ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗ ██╔████╔██║███████║██╔████╔██║██████╔╝███████║ ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║ ██║ ╚═╝ ██║██║ ██║██║ ╚═╝ ██║██████╔╝██║ ██║ ╚═╝ ╚═╝╚═╝ ╚═╝╚═╝ ╚═╝╚═════╝ ╚═╝ ╚═╝ mamba (0.13.0) supported by @QuantStack GitHub: https://github.com/mamba-org/mamba Twitter: https://twitter.com/QuantStack █████████████████████████████████████████████████████████████ Looking for: [&#39;fastai&#39;] fastchan/noarch [=&gt; ] (--:--) No change fastchan/noarch [====================] (00m:00s) No change fastchan/osx-64 [=&gt; ] (--:--) No change fastchan/osx-64 [====================] (00m:00s) No change pkgs/main/osx-64 [=&gt; ] (--:--) No change pkgs/main/osx-64 [====================] (00m:00s) No change pkgs/r/osx-64 [&gt; ] (--:--) No change pkgs/r/osx-64 [====================] (00m:00s) No change pkgs/main/noarch [&gt; ] (--:--) No change pkgs/main/noarch [====================] (00m:00s) No change pkgs/r/noarch [=&gt; ] (--:--) No change pkgs/r/noarch [====================] (00m:00s) No change Transaction Prefix: /usr/local/anaconda3/envs/fastai All requested packages already installed . Now I have to load fastai and I can get the utilities I want. . from fastai.tabular.all import * . Path.cwd() . Path(&#39;/Users/nissan/code/team-fast-tabulous/_notebooks&#39;) . os.chdir(&#39;../_data&#39;) Path.cwd() . Path(&#39;/Users/nissan/code/team-fast-tabulous/_data&#39;) . !kaggle competitions download -c homesite-quote-conversion . homesite-quote-conversion.zip: Skipping, found more recently modified local copy (use --force to force download) . path = Path.cwd() path.ls() . (#7) [Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/homesite-quote-conversion.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv&#39;)] . Unfortunately, untar_data doesn&#39;t support zip format, so we need another tool, file_extract for this . file_extract(&#39;homesite-quote-conversion.zip&#39;) . path.ls() . (#7) [Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/homesite-quote-conversion.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv&#39;)] . file_extract(&#39;test.csv.zip&#39;) file_extract(&#39;train.csv.zip&#39;) file_extract(&#39;sample_submission.csv.zip&#39;) path.ls() . (#7) [Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/homesite-quote-conversion.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv&#39;)] . And there you have it. I have the uncompressed data available, and can now start doing some exploratory data analysis on it. .",
            "url": "https://redditech.github.io/team-fast-tabulous/jupyter/2021/06/19/Get-Kaggle-Data.html",
            "relUrl": "/jupyter/2021/06/19/Get-Kaggle-Data.html",
            "date": " • Jun 19, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://redditech.github.io/team-fast-tabulous/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://redditech.github.io/team-fast-tabulous/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://redditech.github.io/team-fast-tabulous/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}