{
  
    
        "post0": {
            "title": "Identify problem type",
            "content": "# Install packages recommended in fastbook Ch09 !pip install -Uqq fastbook kaggle waterfallcharts treeinterpreter dtreeviz . |████████████████████████████████| 727kB 7.5MB/s |████████████████████████████████| 61kB 8.9MB/s |████████████████████████████████| 1.2MB 15.7MB/s |████████████████████████████████| 194kB 37.5MB/s |████████████████████████████████| 51kB 9.3MB/s |████████████████████████████████| 61kB 10.4MB/s |████████████████████████████████| 61kB 10.5MB/s Building wheel for waterfallcharts (setup.py) ... done Building wheel for dtreeviz (setup.py) ... done . import fastbook fastbook.setup_book() . Mounted at /content/gdrive . from fastbook import * from fastai.vision.widgets import * from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype from fastai.tabular.all import * from sklearn.ensemble import RandomForestRegressor from sklearn.tree import DecisionTreeRegressor from dtreeviz.trees import * from IPython.display import Image, display_svg, SVG pd.options.display.max_rows = 20 pd.options.display.max_columns = 8 . # Upload your kaggle.json API key btn_upload = widgets.FileUpload(description=&quot;kaggle.json&quot;) btn_upload . # Save credentials cred_path = Path(&#39;~/.kaggle/kaggle.json&#39;).expanduser() if not cred_path.parent.exists(): cred_path.parent.mkdir() if len(btn_upload.data) &gt; 0: with open(cred_path, mode=&quot;wb&quot;) as cred_file: cred_file.write(btn_upload.data[-1]) cred_path.chmod(0o600) . from kaggle import api . # Note that &#39;!pip install kaggle&#39; does not update cli kaggle in Google colab # and is only v1.5.4 while kaggle.api is v1.5.12 !kaggle --version . Kaggle API 1.5.4 . # python kaggle.api is using a more recent version api.__version__ . &#39;1.5.12&#39; . # Get data from kaggle, extract and store in _data path_hqc = (Path.cwd()/&quot;_data&quot;) path_hqc.mkdir(exist_ok=True) Path.BASE_PATH = path_hqc api.competition_download_cli(&#39;homesite-quote-conversion&#39;, path=path_hqc) file_extract(path_hqc/&quot;homesite-quote-conversion.zip&quot;) file_extract(path_hqc/&quot;train.csv.zip&quot;) file_extract(path_hqc/&quot;test.csv.zip&quot;) . 0%| | 0.00/62.0M [00:00&lt;?, ?B/s] . Downloading homesite-quote-conversion.zip to /content/_data . 100%|██████████| 62.0M/62.0M [00:00&lt;00:00, 75.9MB/s] . . # Check what the data looks like df = pd.read_csv(path_hqc/&quot;train.csv&quot;, low_memory=False) df.head() . QuoteNumber Original_Quote_Date QuoteConversion_Flag Field6 ... GeographicField62A GeographicField62B GeographicField63 GeographicField64 . 0 1 | 2013-08-16 | 0 | B | ... | -1 | 10 | N | CA | . 1 2 | 2014-04-22 | 0 | F | ... | -1 | 20 | N | NJ | . 2 4 | 2014-08-25 | 0 | F | ... | -1 | 8 | N | NJ | . 3 6 | 2013-04-15 | 0 | J | ... | -1 | 21 | N | TX | . 4 8 | 2014-01-25 | 0 | E | ... | -1 | 12 | N | IL | . 5 rows × 299 columns . # Check how much data we have and check if QuoteNumber is unique df.shape, len(df[&#39;QuoteNumber&#39;].unique()) # Conclusion: QuoteNumber is unique . ((260753, 299), 260753) . # We don&#39;t want to use QuoteNumber as a feature but we could use it as the index df = df.set_index(&#39;QuoteNumber&#39;) . # Examine data types in train.csv df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: float64(6), int64(264), object(28) memory usage: 594.8+ MB . # Find the 28 fields which do not have numeric datatypes from collections import defaultdict dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) print(&quot;dtypes in train.csv:&quot;, dct_fields_by_dtype.keys()) print(&quot;fields for object dtype:&quot;, dct_fields_by_dtype[np.dtype(&#39;O&#39;)]) print(&quot;number of fields of object dtype:&quot;, len(dct_fields_by_dtype[np.dtype(&#39;O&#39;)])) . dtypes in train.csv: dict_keys([dtype(&#39;O&#39;), dtype(&#39;int64&#39;), dtype(&#39;float64&#39;)]) fields for object dtype: [&#39;Original_Quote_Date&#39;, &#39;Field6&#39;, &#39;Field10&#39;, &#39;Field12&#39;, &#39;CoverageField8&#39;, &#39;CoverageField9&#39;, &#39;SalesField7&#39;, &#39;PersonalField7&#39;, &#39;PersonalField16&#39;, &#39;PersonalField17&#39;, &#39;PersonalField18&#39;, &#39;PersonalField19&#39;, &#39;PropertyField3&#39;, &#39;PropertyField4&#39;, &#39;PropertyField5&#39;, &#39;PropertyField7&#39;, &#39;PropertyField14&#39;, &#39;PropertyField28&#39;, &#39;PropertyField30&#39;, &#39;PropertyField31&#39;, &#39;PropertyField32&#39;, &#39;PropertyField33&#39;, &#39;PropertyField34&#39;, &#39;PropertyField36&#39;, &#39;PropertyField37&#39;, &#39;PropertyField38&#39;, &#39;GeographicField63&#39;, &#39;GeographicField64&#39;] number of fields of object dtype: 28 . # Original_Quote_Date can be converted to datetime df[&#39;Original_Quote_Date&#39;] = pd.to_datetime(df[&#39;Original_Quote_Date&#39;]) # recalculate breakdown now that we have changed dtype of Original_Quote_Date dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: datetime64[ns](1), float64(6), int64(264), object(27) memory usage: 594.8+ MB . # Compare Original_Quote_Date in train.csv and test.csv df_test = pd.read_csv(path_hqc/&quot;test.csv&quot;, low_memory=False) df_test[&quot;Original_Quote_Date&quot;] = pd.to_datetime(df_test[&quot;Original_Quote_Date&quot;]) print(&quot;train.csv&quot;, df[&#39;Original_Quote_Date&#39;].min(), df[&#39;Original_Quote_Date&#39;].max(), df.shape) print(&quot;test.csv &quot;, df_test[&#39;Original_Quote_Date&#39;].min(), df_test[&#39;Original_Quote_Date&#39;].max(), df_test.shape) # Conclusion: overlapping date ranges (in fact identical date ranges) so # don&#39;t need to consider as time series problem . train.csv 2013-01-01 00:00:00 2015-05-18 00:00:00 (260753, 298) test.csv 2013-01-01 00:00:00 2015-05-18 00:00:00 (173836, 298) . # Check the non-numeric values in other object fields for col in dct_fields_by_dtype[np.dtype(&#39;O&#39;)]: print(f&quot;{col:20s} {df[col].unique()}&quot;) . Field6 [&#39;B&#39; &#39;F&#39; &#39;J&#39; &#39;E&#39; &#39;C&#39; &#39;K&#39; &#39;A&#39; &#39;D&#39;] Field10 [&#39;965&#39; &#39;548&#39; &#39;1,165&#39; &#39;1,487&#39; &#39;935&#39; &#39;564&#39; &#39;1,113&#39; &#39;1,480&#39;] Field12 [&#39;N&#39; &#39;Y&#39;] CoverageField8 [&#39;T&#39; &#39;Y&#39; &#39;X&#39; &#39;W&#39; &#39;V&#39; &#39;U&#39; &#39;Z&#39;] CoverageField9 [&#39;D&#39; &#39;E&#39; &#39;J&#39; &#39;F&#39; &#39;A&#39; &#39;G&#39; &#39;K&#39; &#39;C&#39; &#39;L&#39; &#39;B&#39; &#39;I&#39; &#39;H&#39;] SalesField7 [&#39;V&#39; &#39;P&#39; &#39;K&#39; &#39;R&#39; &#39;T&#39; &#39;Q&#39; &#39;M&#39;] PersonalField7 [&#39;N&#39; &#39;Y&#39; nan] PersonalField16 [&#39;ZA&#39; &#39;XB&#39; &#39;ZH&#39; &#39;XO&#39; &#39;YE&#39; &#39;XR&#39; &#39;ZG&#39; &#39;ZF&#39; &#39;XW&#39; &#39;XS&#39; &#39;ZT&#39; &#39;XD&#39; &#39;XH&#39; &#39;XM&#39; &#39;YH&#39; &#39;ZD&#39; &#39;XJ&#39; &#39;ZN&#39; &#39;YF&#39; &#39;XX&#39; &#39;XL&#39; &#39;XQ&#39; &#39;ZJ&#39; &#39;ZR&#39; &#39;ZW&#39; &#39;XE&#39; &#39;XC&#39; &#39;ZK&#39; &#39;XK&#39; &#39;ZC&#39; &#39;XZ&#39; &#39;XI&#39; &#39;ZE&#39; &#39;ZU&#39; &#39;YI&#39; &#39;XP&#39; &#39;ZO&#39; &#39;ZP&#39; &#39;ZB&#39; &#39;XF&#39; &#39;ZS&#39; &#39;XT&#39; &#39;XY&#39; &#39;ZQ&#39; &#39;ZI&#39; &#39;XV&#39; &#39;XU&#39; &#39;XN&#39; &#39;ZV&#39; &#39;ZL&#39;] PersonalField17 [&#39;ZE&#39; &#39;YJ&#39; &#39;XS&#39; &#39;XE&#39; &#39;XU&#39; &#39;ZQ&#39; &#39;YY&#39; &#39;XV&#39; &#39;ZF&#39; &#39;XK&#39; &#39;YS&#39; &#39;ZK&#39; &#39;YF&#39; &#39;YV&#39; &#39;XG&#39; &#39;ZL&#39; &#39;ZH&#39; &#39;ZW&#39; &#39;XH&#39; &#39;ZU&#39; &#39;YH&#39; &#39;XC&#39; &#39;ZV&#39; &#39;XR&#39; &#39;ZI&#39; &#39;XX&#39; &#39;YR&#39; &#39;XW&#39; &#39;ZC&#39; &#39;YZ&#39; &#39;YU&#39; &#39;YX&#39; &#39;ZA&#39; &#39;ZP&#39; &#39;XI&#39; &#39;YN&#39; &#39;YL&#39; &#39;YK&#39; &#39;ZN&#39; &#39;XT&#39; &#39;ZT&#39; &#39;XQ&#39; &#39;XB&#39; &#39;YI&#39; &#39;YM&#39; &#39;XL&#39; &#39;YQ&#39; &#39;ZG&#39; &#39;ZS&#39; &#39;YT&#39; &#39;ZO&#39; &#39;YE&#39; &#39;XN&#39; &#39;ZM&#39; &#39;XM&#39; &#39;YG&#39; &#39;YP&#39; &#39;XD&#39; &#39;ZD&#39; &#39;YW&#39; &#39;XJ&#39; &#39;ZB&#39; &#39;XP&#39; &#39;XO&#39; &#39;ZR&#39; &#39;XY&#39;] PersonalField18 [&#39;XR&#39; &#39;YE&#39; &#39;YP&#39; &#39;YI&#39; &#39;XQ&#39; &#39;ZW&#39; &#39;XT&#39; &#39;XF&#39; &#39;XS&#39; &#39;YG&#39; &#39;ZF&#39; &#39;XZ&#39; &#39;XI&#39; &#39;XK&#39; &#39;YF&#39; &#39;ZE&#39; &#39;YQ&#39; &#39;ZP&#39; &#39;YL&#39; &#39;ZD&#39; &#39;XW&#39; &#39;YN&#39; &#39;YK&#39; &#39;ZJ&#39; &#39;ZK&#39; &#39;ZC&#39; &#39;XU&#39; &#39;ZN&#39; &#39;XP&#39; &#39;XL&#39; &#39;XM&#39; &#39;ZL&#39; &#39;XC&#39; &#39;ZH&#39; &#39;XG&#39; &#39;XN&#39; &#39;XY&#39; &#39;ZQ&#39; &#39;XO&#39; &#39;ZT&#39; &#39;XJ&#39; &#39;ZA&#39; &#39;ZU&#39; &#39;XE&#39; &#39;ZV&#39; &#39;ZS&#39; &#39;YR&#39; &#39;YH&#39; &#39;YJ&#39; &#39;ZR&#39; &#39;ZO&#39; &#39;YO&#39; &#39;ZM&#39; &#39;XD&#39; &#39;YM&#39; &#39;XX&#39; &#39;ZB&#39; &#39;XH&#39; &#39;XV&#39; &#39;ZG&#39; &#39;ZI&#39;] PersonalField19 [&#39;XD&#39; &#39;XT&#39; &#39;XC&#39; &#39;XX&#39; &#39;ZQ&#39; &#39;ZT&#39; &#39;ZO&#39; &#39;YJ&#39; &#39;ZN&#39; &#39;YH&#39; &#39;ZI&#39; &#39;YN&#39; &#39;YF&#39; &#39;YK&#39; &#39;XY&#39; &#39;XI&#39; &#39;ZA&#39; &#39;ZW&#39; &#39;ZV&#39; &#39;XU&#39; &#39;ZL&#39; &#39;XK&#39; &#39;XW&#39; &#39;XF&#39; &#39;ZK&#39; &#39;YE&#39; &#39;XB&#39; &#39;XZ&#39; &#39;XP&#39; &#39;ZJ&#39; &#39;YM&#39; &#39;XO&#39; &#39;YG&#39; &#39;XN&#39; &#39;ZR&#39; &#39;ZE&#39; &#39;ZB&#39; &#39;ZG&#39; &#39;YL&#39; &#39;ZF&#39; &#39;XR&#39; &#39;XJ&#39; &#39;XM&#39; &#39;ZP&#39; &#39;XQ&#39; &#39;XV&#39; &#39;ZH&#39; &#39;XE&#39; &#39;ZU&#39; &#39;ZM&#39; &#39;XG&#39; &#39;ZD&#39; &#39;XH&#39; &#39;XL&#39; &#39;YI&#39; &#39;XS&#39; &#39;ZC&#39;] PropertyField3 [&#39;N&#39; &#39;Y&#39; nan] PropertyField4 [&#39;N&#39; &#39;Y&#39; nan] PropertyField5 [&#39;Y&#39; &#39;N&#39;] PropertyField7 [&#39;O&#39; &#39;N&#39; &#39;R&#39; &#39;D&#39; &#39;S&#39; &#39;J&#39; &#39;I&#39; &#39;Q&#39; &#39;A&#39; &#39;K&#39; &#39;G&#39; &#39;F&#39; &#39;H&#39; &#39;E&#39; &#39;L&#39; &#39;C&#39; &#39;P&#39; &#39;M&#39; &#39;B&#39;] PropertyField14 [&#39;C&#39; &#39;B&#39; &#39;A&#39; &#39;D&#39;] PropertyField28 [&#39;B&#39; &#39;D&#39; &#39;A&#39; &#39;C&#39;] PropertyField30 [&#39;N&#39; &#39;Y&#39;] PropertyField31 [&#39;N&#39; &#39;O&#39; &#39;K&#39; &#39;M&#39;] PropertyField32 [&#39;Y&#39; &#39;N&#39; nan] PropertyField33 [&#39;G&#39; &#39;H&#39; &#39;E&#39; &#39;F&#39;] PropertyField34 [&#39;Y&#39; &#39;N&#39; nan] PropertyField36 [&#39;N&#39; &#39;Y&#39; nan] PropertyField37 [&#39;N&#39; &#39;Y&#39;] PropertyField38 [&#39;N&#39; &#39;Y&#39; nan] GeographicField63 [&#39;N&#39; &#39;Y&#39; &#39; &#39;] GeographicField64 [&#39;CA&#39; &#39;NJ&#39; &#39;TX&#39; &#39;IL&#39;] . # Field10 looks like integers stored as strings so convert to ints df[&#39;Field10&#39;] = df[&#39;Field10&#39;].str.replace(&quot;,&quot;, &quot;&quot;).astype(int) df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: datetime64[ns](1), float64(6), int64(265), object(26) memory usage: 594.8+ MB . # recalculate breakdown now that we have changed dtype of Field10 dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) .",
            "url": "https://redditech.github.io/team-fast-tabulous/jupyter/2021/06/20/Identify-problem-type.html",
            "relUrl": "/jupyter/2021/06/20/Identify-problem-type.html",
            "date": " • Jun 20, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Cleaning data and identifying problem type",
            "content": "!pip install -Uqq fastbook kaggle waterfallcharts treeinterpreter dtreeviz . |████████████████████████████████| 727kB 7.5MB/s |████████████████████████████████| 61kB 8.9MB/s |████████████████████████████████| 1.2MB 15.7MB/s |████████████████████████████████| 194kB 37.5MB/s |████████████████████████████████| 51kB 9.3MB/s |████████████████████████████████| 61kB 10.4MB/s |████████████████████████████████| 61kB 10.5MB/s Building wheel for waterfallcharts (setup.py) ... done Building wheel for dtreeviz (setup.py) ... done . import fastbook fastbook.setup_book() . Mounted at /content/gdrive . from fastbook import * from fastai.vision.widgets import * from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype from fastai.tabular.all import * from sklearn.ensemble import RandomForestRegressor from sklearn.tree import DecisionTreeRegressor from dtreeviz.trees import * from IPython.display import Image, display_svg, SVG pd.options.display.max_rows = 20 pd.options.display.max_columns = 8 . btn_upload = widgets.FileUpload(description=&quot;kaggle.json&quot;) btn_upload . cred_path = Path(&#39;~/.kaggle/kaggle.json&#39;).expanduser() if not cred_path.parent.exists(): cred_path.parent.mkdir() if len(btn_upload.data) &gt; 0: with open(cred_path, mode=&quot;wb&quot;) as cred_file: cred_file.write(btn_upload.data[-1]) cred_path.chmod(0o600) . from kaggle import api . # and is only v1.5.4 while kaggle.api is v1.5.12 !kaggle --version . Kaggle API 1.5.4 . api.__version__ . &#39;1.5.12&#39; . path_hqc = (Path.cwd()/&quot;_data&quot;) path_hqc.mkdir(exist_ok=True) Path.BASE_PATH = path_hqc api.competition_download_cli(&#39;homesite-quote-conversion&#39;, path=path_hqc) file_extract(path_hqc/&quot;homesite-quote-conversion.zip&quot;) file_extract(path_hqc/&quot;train.csv.zip&quot;) file_extract(path_hqc/&quot;test.csv.zip&quot;) . 0%| | 0.00/62.0M [00:00&lt;?, ?B/s] . Downloading homesite-quote-conversion.zip to /content/_data . 100%|██████████| 62.0M/62.0M [00:00&lt;00:00, 75.9MB/s] . . df = pd.read_csv(path_hqc/&quot;train.csv&quot;, low_memory=False) df.head() . QuoteNumber Original_Quote_Date QuoteConversion_Flag Field6 ... GeographicField62A GeographicField62B GeographicField63 GeographicField64 . 0 1 | 2013-08-16 | 0 | B | ... | -1 | 10 | N | CA | . 1 2 | 2014-04-22 | 0 | F | ... | -1 | 20 | N | NJ | . 2 4 | 2014-08-25 | 0 | F | ... | -1 | 8 | N | NJ | . 3 6 | 2013-04-15 | 0 | J | ... | -1 | 21 | N | TX | . 4 8 | 2014-01-25 | 0 | E | ... | -1 | 12 | N | IL | . 5 rows × 299 columns . df.shape, len(df[&#39;QuoteNumber&#39;].unique()) # Conclusion: QuoteNumber is unique . ((260753, 299), 260753) . df = df.set_index(&#39;QuoteNumber&#39;) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: float64(6), int64(264), object(28) memory usage: 594.8+ MB . from collections import defaultdict dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) print(&quot;dtypes in train.csv:&quot;, dct_fields_by_dtype.keys()) print(&quot;fields for object dtype:&quot;, dct_fields_by_dtype[np.dtype(&#39;O&#39;)]) print(&quot;number of fields of object dtype:&quot;, len(dct_fields_by_dtype[np.dtype(&#39;O&#39;)])) . dtypes in train.csv: dict_keys([dtype(&#39;O&#39;), dtype(&#39;int64&#39;), dtype(&#39;float64&#39;)]) fields for object dtype: [&#39;Original_Quote_Date&#39;, &#39;Field6&#39;, &#39;Field10&#39;, &#39;Field12&#39;, &#39;CoverageField8&#39;, &#39;CoverageField9&#39;, &#39;SalesField7&#39;, &#39;PersonalField7&#39;, &#39;PersonalField16&#39;, &#39;PersonalField17&#39;, &#39;PersonalField18&#39;, &#39;PersonalField19&#39;, &#39;PropertyField3&#39;, &#39;PropertyField4&#39;, &#39;PropertyField5&#39;, &#39;PropertyField7&#39;, &#39;PropertyField14&#39;, &#39;PropertyField28&#39;, &#39;PropertyField30&#39;, &#39;PropertyField31&#39;, &#39;PropertyField32&#39;, &#39;PropertyField33&#39;, &#39;PropertyField34&#39;, &#39;PropertyField36&#39;, &#39;PropertyField37&#39;, &#39;PropertyField38&#39;, &#39;GeographicField63&#39;, &#39;GeographicField64&#39;] number of fields of object dtype: 28 . df[&#39;Original_Quote_Date&#39;] = pd.to_datetime(df[&#39;Original_Quote_Date&#39;]) # recalculate breakdown now that we have changed dtype of Original_Quote_Date dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: datetime64[ns](1), float64(6), int64(264), object(27) memory usage: 594.8+ MB . df_test = pd.read_csv(path_hqc/&quot;test.csv&quot;, low_memory=False) df_test[&quot;Original_Quote_Date&quot;] = pd.to_datetime(df_test[&quot;Original_Quote_Date&quot;]) print(&quot;train.csv&quot;, df[&#39;Original_Quote_Date&#39;].min(), df[&#39;Original_Quote_Date&#39;].max(), df.shape) print(&quot;test.csv &quot;, df_test[&#39;Original_Quote_Date&#39;].min(), df_test[&#39;Original_Quote_Date&#39;].max(), df_test.shape) # Conclusion: overlapping date ranges (in fact identical date ranges) so # don&#39;t need to consider as time series problem . train.csv 2013-01-01 00:00:00 2015-05-18 00:00:00 (260753, 298) test.csv 2013-01-01 00:00:00 2015-05-18 00:00:00 (173836, 298) . for col in dct_fields_by_dtype[np.dtype(&#39;O&#39;)]: print(f&quot;{col:20s} {df[col].unique()}&quot;) . Field6 [&#39;B&#39; &#39;F&#39; &#39;J&#39; &#39;E&#39; &#39;C&#39; &#39;K&#39; &#39;A&#39; &#39;D&#39;] Field10 [&#39;965&#39; &#39;548&#39; &#39;1,165&#39; &#39;1,487&#39; &#39;935&#39; &#39;564&#39; &#39;1,113&#39; &#39;1,480&#39;] Field12 [&#39;N&#39; &#39;Y&#39;] CoverageField8 [&#39;T&#39; &#39;Y&#39; &#39;X&#39; &#39;W&#39; &#39;V&#39; &#39;U&#39; &#39;Z&#39;] CoverageField9 [&#39;D&#39; &#39;E&#39; &#39;J&#39; &#39;F&#39; &#39;A&#39; &#39;G&#39; &#39;K&#39; &#39;C&#39; &#39;L&#39; &#39;B&#39; &#39;I&#39; &#39;H&#39;] SalesField7 [&#39;V&#39; &#39;P&#39; &#39;K&#39; &#39;R&#39; &#39;T&#39; &#39;Q&#39; &#39;M&#39;] PersonalField7 [&#39;N&#39; &#39;Y&#39; nan] PersonalField16 [&#39;ZA&#39; &#39;XB&#39; &#39;ZH&#39; &#39;XO&#39; &#39;YE&#39; &#39;XR&#39; &#39;ZG&#39; &#39;ZF&#39; &#39;XW&#39; &#39;XS&#39; &#39;ZT&#39; &#39;XD&#39; &#39;XH&#39; &#39;XM&#39; &#39;YH&#39; &#39;ZD&#39; &#39;XJ&#39; &#39;ZN&#39; &#39;YF&#39; &#39;XX&#39; &#39;XL&#39; &#39;XQ&#39; &#39;ZJ&#39; &#39;ZR&#39; &#39;ZW&#39; &#39;XE&#39; &#39;XC&#39; &#39;ZK&#39; &#39;XK&#39; &#39;ZC&#39; &#39;XZ&#39; &#39;XI&#39; &#39;ZE&#39; &#39;ZU&#39; &#39;YI&#39; &#39;XP&#39; &#39;ZO&#39; &#39;ZP&#39; &#39;ZB&#39; &#39;XF&#39; &#39;ZS&#39; &#39;XT&#39; &#39;XY&#39; &#39;ZQ&#39; &#39;ZI&#39; &#39;XV&#39; &#39;XU&#39; &#39;XN&#39; &#39;ZV&#39; &#39;ZL&#39;] PersonalField17 [&#39;ZE&#39; &#39;YJ&#39; &#39;XS&#39; &#39;XE&#39; &#39;XU&#39; &#39;ZQ&#39; &#39;YY&#39; &#39;XV&#39; &#39;ZF&#39; &#39;XK&#39; &#39;YS&#39; &#39;ZK&#39; &#39;YF&#39; &#39;YV&#39; &#39;XG&#39; &#39;ZL&#39; &#39;ZH&#39; &#39;ZW&#39; &#39;XH&#39; &#39;ZU&#39; &#39;YH&#39; &#39;XC&#39; &#39;ZV&#39; &#39;XR&#39; &#39;ZI&#39; &#39;XX&#39; &#39;YR&#39; &#39;XW&#39; &#39;ZC&#39; &#39;YZ&#39; &#39;YU&#39; &#39;YX&#39; &#39;ZA&#39; &#39;ZP&#39; &#39;XI&#39; &#39;YN&#39; &#39;YL&#39; &#39;YK&#39; &#39;ZN&#39; &#39;XT&#39; &#39;ZT&#39; &#39;XQ&#39; &#39;XB&#39; &#39;YI&#39; &#39;YM&#39; &#39;XL&#39; &#39;YQ&#39; &#39;ZG&#39; &#39;ZS&#39; &#39;YT&#39; &#39;ZO&#39; &#39;YE&#39; &#39;XN&#39; &#39;ZM&#39; &#39;XM&#39; &#39;YG&#39; &#39;YP&#39; &#39;XD&#39; &#39;ZD&#39; &#39;YW&#39; &#39;XJ&#39; &#39;ZB&#39; &#39;XP&#39; &#39;XO&#39; &#39;ZR&#39; &#39;XY&#39;] PersonalField18 [&#39;XR&#39; &#39;YE&#39; &#39;YP&#39; &#39;YI&#39; &#39;XQ&#39; &#39;ZW&#39; &#39;XT&#39; &#39;XF&#39; &#39;XS&#39; &#39;YG&#39; &#39;ZF&#39; &#39;XZ&#39; &#39;XI&#39; &#39;XK&#39; &#39;YF&#39; &#39;ZE&#39; &#39;YQ&#39; &#39;ZP&#39; &#39;YL&#39; &#39;ZD&#39; &#39;XW&#39; &#39;YN&#39; &#39;YK&#39; &#39;ZJ&#39; &#39;ZK&#39; &#39;ZC&#39; &#39;XU&#39; &#39;ZN&#39; &#39;XP&#39; &#39;XL&#39; &#39;XM&#39; &#39;ZL&#39; &#39;XC&#39; &#39;ZH&#39; &#39;XG&#39; &#39;XN&#39; &#39;XY&#39; &#39;ZQ&#39; &#39;XO&#39; &#39;ZT&#39; &#39;XJ&#39; &#39;ZA&#39; &#39;ZU&#39; &#39;XE&#39; &#39;ZV&#39; &#39;ZS&#39; &#39;YR&#39; &#39;YH&#39; &#39;YJ&#39; &#39;ZR&#39; &#39;ZO&#39; &#39;YO&#39; &#39;ZM&#39; &#39;XD&#39; &#39;YM&#39; &#39;XX&#39; &#39;ZB&#39; &#39;XH&#39; &#39;XV&#39; &#39;ZG&#39; &#39;ZI&#39;] PersonalField19 [&#39;XD&#39; &#39;XT&#39; &#39;XC&#39; &#39;XX&#39; &#39;ZQ&#39; &#39;ZT&#39; &#39;ZO&#39; &#39;YJ&#39; &#39;ZN&#39; &#39;YH&#39; &#39;ZI&#39; &#39;YN&#39; &#39;YF&#39; &#39;YK&#39; &#39;XY&#39; &#39;XI&#39; &#39;ZA&#39; &#39;ZW&#39; &#39;ZV&#39; &#39;XU&#39; &#39;ZL&#39; &#39;XK&#39; &#39;XW&#39; &#39;XF&#39; &#39;ZK&#39; &#39;YE&#39; &#39;XB&#39; &#39;XZ&#39; &#39;XP&#39; &#39;ZJ&#39; &#39;YM&#39; &#39;XO&#39; &#39;YG&#39; &#39;XN&#39; &#39;ZR&#39; &#39;ZE&#39; &#39;ZB&#39; &#39;ZG&#39; &#39;YL&#39; &#39;ZF&#39; &#39;XR&#39; &#39;XJ&#39; &#39;XM&#39; &#39;ZP&#39; &#39;XQ&#39; &#39;XV&#39; &#39;ZH&#39; &#39;XE&#39; &#39;ZU&#39; &#39;ZM&#39; &#39;XG&#39; &#39;ZD&#39; &#39;XH&#39; &#39;XL&#39; &#39;YI&#39; &#39;XS&#39; &#39;ZC&#39;] PropertyField3 [&#39;N&#39; &#39;Y&#39; nan] PropertyField4 [&#39;N&#39; &#39;Y&#39; nan] PropertyField5 [&#39;Y&#39; &#39;N&#39;] PropertyField7 [&#39;O&#39; &#39;N&#39; &#39;R&#39; &#39;D&#39; &#39;S&#39; &#39;J&#39; &#39;I&#39; &#39;Q&#39; &#39;A&#39; &#39;K&#39; &#39;G&#39; &#39;F&#39; &#39;H&#39; &#39;E&#39; &#39;L&#39; &#39;C&#39; &#39;P&#39; &#39;M&#39; &#39;B&#39;] PropertyField14 [&#39;C&#39; &#39;B&#39; &#39;A&#39; &#39;D&#39;] PropertyField28 [&#39;B&#39; &#39;D&#39; &#39;A&#39; &#39;C&#39;] PropertyField30 [&#39;N&#39; &#39;Y&#39;] PropertyField31 [&#39;N&#39; &#39;O&#39; &#39;K&#39; &#39;M&#39;] PropertyField32 [&#39;Y&#39; &#39;N&#39; nan] PropertyField33 [&#39;G&#39; &#39;H&#39; &#39;E&#39; &#39;F&#39;] PropertyField34 [&#39;Y&#39; &#39;N&#39; nan] PropertyField36 [&#39;N&#39; &#39;Y&#39; nan] PropertyField37 [&#39;N&#39; &#39;Y&#39;] PropertyField38 [&#39;N&#39; &#39;Y&#39; nan] GeographicField63 [&#39;N&#39; &#39;Y&#39; &#39; &#39;] GeographicField64 [&#39;CA&#39; &#39;NJ&#39; &#39;TX&#39; &#39;IL&#39;] . df[&#39;Field10&#39;] = df[&#39;Field10&#39;].str.replace(&quot;,&quot;, &quot;&quot;).astype(int) df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 260753 entries, 1 to 434588 Columns: 298 entries, Original_Quote_Date to GeographicField64 dtypes: datetime64[ns](1), float64(6), int64(265), object(26) memory usage: 594.8+ MB . dct_fields_by_dtype = defaultdict(list) for i, dt in enumerate(df.dtypes): dct_fields_by_dtype[dt].append(df.dtypes.index[i]) .",
            "url": "https://redditech.github.io/team-fast-tabulous/jupyter/2021/06/20/Clean-data-and-identify-problem-type.html",
            "relUrl": "/jupyter/2021/06/20/Clean-data-and-identify-problem-type.html",
            "date": " • Jun 20, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Getting Kaggle Data for Homesite",
            "content": "Introduction . This notebook is a demonstration of what I did to get the Homesite competition data from Kaggle. . Tools . If you haven&#39;t installed the Kaggle tools, you would need to do so like this . !pip install kaggle --upgrade . Requirement already satisfied: kaggle in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (1.5.12) Requirement already satisfied: python-dateutil in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2.8.1) Requirement already satisfied: certifi in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2021.5.30) Requirement already satisfied: requests in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2.25.1) Requirement already satisfied: tqdm in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (4.59.0) Requirement already satisfied: urllib3 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (1.26.4) Requirement already satisfied: python-slugify in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (5.0.2) Requirement already satisfied: six&gt;=1.10 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (1.16.0) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests-&gt;kaggle) (4.0.0) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests-&gt;kaggle) (2.10) . Then you need to download your Kaggle key following the instructions here . You may need to create the ~/.kaggle directory manually before copying the downloaded file kaggle.json file to that folder. . Follow the instructions as coded to download the kaggle data. For me, I use a _data folder that is excluded from checkins in the .gitignore to make sure I do not inadvertently upload it when I check in any changes to the repository, since I&#39;m writing this blog post as I am coding. I&#39;m not using any of the tabular stuff from fastai library yet, but I want to use some of the nice utility functions it gives me to make sure I do the command line stuff correctly and capture it in the notebook. So I need to install it. . !mamba install -c fastchan fastai -y . __ __ __ __ / / / / / / / / ███████████████/ /██/ /██/ /██/ /████████████████████████ / / / / / ____ / / _/ _/ _/ o __, / _/ _____/ ` |/ ███╗ ███╗ █████╗ ███╗ ███╗██████╗ █████╗ ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗ ██╔████╔██║███████║██╔████╔██║██████╔╝███████║ ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║ ██║ ╚═╝ ██║██║ ██║██║ ╚═╝ ██║██████╔╝██║ ██║ ╚═╝ ╚═╝╚═╝ ╚═╝╚═╝ ╚═╝╚═════╝ ╚═╝ ╚═╝ mamba (0.13.0) supported by @QuantStack GitHub: https://github.com/mamba-org/mamba Twitter: https://twitter.com/QuantStack █████████████████████████████████████████████████████████████ Looking for: [&#39;fastai&#39;] pkgs/main/noarch [&gt; ] (--:--) No change pkgs/main/noarch [====================] (00m:00s) No change pkgs/main/osx-64 [&gt; ] (--:--) No change pkgs/main/osx-64 [====================] (00m:00s) No change pkgs/r/osx-64 [=&gt; ] (--:--) No change pkgs/r/osx-64 [====================] (00m:00s) No change pkgs/r/noarch [=&gt; ] (--:--) No change pkgs/r/noarch [====================] (00m:00s) No change fastchan/osx-64 [=&gt; ] (--:--) No change fastchan/osx-64 [====================] (00m:00s) No change fastchan/noarch [&gt; ] (--:--) No change fastchan/noarch [====================] (00m:00s) No change Transaction Prefix: /usr/local/anaconda3/envs/fastai Updating specs: - fastai Package Version Build Channel Size ─────────────────────────────────────────────────────── Install: ─────────────────────────────────────────────────────── fastai 2.4 py_0 fastchan/noarch Cached Summary: Install: 1 packages Total download: 0 B ─────────────────────────────────────────────────────── Preparing transaction: done Verifying transaction: done Executing transaction: done . Now I have to load fastai and I can get the utilities I want. . from fastai.tabular.all import * . Path.cwd() . Path(&#39;/Users/nissan/code/team-fast-tabulous/_notebooks&#39;) . os.chdir(&#39;../_data&#39;) Path.cwd() . Path(&#39;/Users/nissan/code/team-fast-tabulous/_data&#39;) . !kaggle competitions download -c homesite-quote-conversion . Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run &#39;chmod 600 /Users/nissan/.kaggle/kaggle.json&#39; Downloading homesite-quote-conversion.zip to /Users/nissan/code/team-fast-tabulous/_data 100%|█████████████████████████████████████▉| 62.0M/62.0M [00:05&lt;00:00, 11.3MB/s] 100%|██████████████████████████████████████| 62.0M/62.0M [00:05&lt;00:00, 11.0MB/s] . path.ls() . (#1) [Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/homesite-quote-conversion.zip&#39;)] . Unfortunately, untar_data doesn&#39;t support zip format, so we need another tool, file_extract for this . file_extract(&#39;homesite-quote-conversion.zip&#39;) . path.ls() . (#4) [Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/homesite-quote-conversion.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv.zip&#39;)] . file_extract(&#39;test.csv.zip&#39;) file_extract(&#39;train.csv.zip&#39;) file_extract(&#39;sample_submission.csv.zip&#39;) path.ls() . (#7) [Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/homesite-quote-conversion.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/test.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/train.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv.zip&#39;),Path(&#39;/Users/nissan/code/team-fast-tabulous/_data/sample_submission.csv&#39;)] . And there you have it. I have the uncompressed data available, and can now start doing some exploratory data analysis on it. .",
            "url": "https://redditech.github.io/team-fast-tabulous/jupyter/2021/06/19/test-Get-Kaggle-Data.html",
            "relUrl": "/jupyter/2021/06/19/test-Get-Kaggle-Data.html",
            "date": " • Jun 19, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://redditech.github.io/team-fast-tabulous/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://redditech.github.io/team-fast-tabulous/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://redditech.github.io/team-fast-tabulous/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}